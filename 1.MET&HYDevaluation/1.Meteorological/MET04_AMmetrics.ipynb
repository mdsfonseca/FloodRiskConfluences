{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "# import geopandas as gp\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import lmom as lmom\n",
    "import MetFunctions02 as mf1\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import norm\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532537d8",
   "metadata": {},
   "source": [
    "Open the 50000 AM peak files\n",
    "\n",
    "Random selection according to N, pero set of AM\n",
    "\n",
    "Calculate the metrics per confluence (100 runs pero sample)  and stores them according to the confluences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c2583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a928146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randSet(am1, n):  #CHANGED --> now POT also uses the window as an imput\n",
    "    \"\"\"\n",
    "    Creates DataFrame set of random Annual Maxima (AM) of one point\n",
    "    AM1: DataFrame with the AM \n",
    "    n: size of the random set e.g. (50)\n",
    "    Returns:\n",
    "        set1: random set of AM of Point1 and concurrent flow of Point2\n",
    "    \"\"\"\n",
    "    am1['ind'] = np.arange(len(am1))\n",
    "    randomindex1 = np.random.choice(am1.ind, size=n, replace=False)\n",
    "    set1 = pd.DataFrame()\n",
    "    for i in range(n):\n",
    "        set1 = set1.append(am1.loc[am1.ind == randomindex1[i]])\n",
    "    return set1\n",
    "\n",
    "def randSetR(am1, n):  #CHANGED --> now POT also uses the window as an imput\n",
    "    \"\"\"\n",
    "    Creates DataFrame set of random Annual Maxima (AM) of one point\n",
    "    AM1: DataFrame with the AM \n",
    "    n: size of the random set e.g. (50)\n",
    "    Returns:\n",
    "        set1: random set of AM of Point1 and concurrent flow of Point2\n",
    "    \"\"\"\n",
    "    am1['ind'] = np.arange(len(am1))\n",
    "    randomindex1 = np.random.choice(am1.ind, size=n, replace=True)\n",
    "    set1 = pd.DataFrame()\n",
    "    for i in range(n):\n",
    "        set1 = set1.append(am1.loc[am1.ind == randomindex1[i]])\n",
    "    return set1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57719ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataframes to be filled per N-sample\n",
    "\n",
    "def dfN():\n",
    "    conf_AM = pd.read_csv('Confluences_wnames.csv', delimiter=';')\n",
    "    conf_AM['rho_mean'] = ''\n",
    "    conf_AM['rho_std'] = ''\n",
    "#     conf_AM['rho_cv'] = ''\n",
    "    conf_AM['S1avg_mean'] = ''\n",
    "    conf_AM['S1avg_std'] = ''\n",
    "    conf_AM['S1std_mean'] = ''\n",
    "    conf_AM['S1std_std'] = ''\n",
    "#     conf_AM['S1avg_cv'] = ''\n",
    "    conf_AM['S2avg_mean'] = ''\n",
    "    conf_AM['S2avg_std'] = ''\n",
    "    conf_AM['S2std_mean'] = ''\n",
    "    conf_AM['S2std_std'] = ''\n",
    "#     conf_AM['S2avg_cv'] = ''\n",
    "    return conf_AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3387126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ALL the dataframes per AM set, per N-sample size\n",
    "# extra = ''\n",
    "# for A in ('AM1', 'AM2', 'AM3'):\n",
    "#     for n in ('100', '500', '1000', '5000', '10000', '25000', '50000'): #'100', \n",
    "#         globals()[f'C_{A}_n{n}{extra}'] = dfN()\n",
    "\n",
    "# Create 1 w/extra info  N=100 r=50\n",
    "extra = 'r5d'\n",
    "n = 100 #100, 500, 1000, 5000, 10000, 25000, 50000\n",
    "for A in ('AM1', 'AM2', 'AM3'): #'AM1', \n",
    "    globals()[f'C_{A}_n{n}{extra}'] = dfN()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04873c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ALL the dataframes\n",
    "# desc = '' #SAVE'rain1d', 'snow', 'rain5d', (ONLY N=1000)'r50'\n",
    "# extra = '' #RUN 'rain1d', 'snow', 'rain5d', (ONLY N=1000)'r50'\n",
    "# for A in (1, 2, 3):\n",
    "#     for n in (100, 500, 1000, 5000, 10000, 25000, 50000):\n",
    "#         sv = r\"P:\\11206883-006-dar-cloud-computing\\RhineFiles\\MET\\METmetrics\\C_AM%d\" %A + r\"_n%d\" %n  + desc + r\".pkl\"\n",
    "#         globals()[f'C_AM{A}_n{n}{extra}'].to_pickle(sv)\n",
    "\n",
    "# Save 1 dataframe\n",
    "desc = 'check' #'rain1d', 'snow', 'rain5d', (ONLY N=1000)'r50'\n",
    "extra = '' #RUN 'rain1d', 'snow', 'rain5d', (ONLY N=1000)'r50'\n",
    "n = 1000 #100, 500, 1000, 5000, 10000, 25000, 50000\n",
    "for A in (2, 3):\n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\RhineFiles\\MET\\AM-Nmetrics\\C_AM%d\" %A + r\"_n%d\" %n  + desc + r\".pkl\"\n",
    "#     sv = r\"P:\\11206883-006-dar-cloud-computing\\RhineFiles\\MET\\METmetrics\\C_AM%d\" %A + r\"_n%d\" %n  + desc + r\".pkl\"\n",
    "    globals()[f'C_AM{A}_n{n}{extra}'].to_pickle(sv)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0582559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open ALL the dataframes\n",
    "# desc = '' #OPEN 'rain1d', 'snow', 'rain5d', (ONLY N=1000)'r50'\n",
    "# extra = '' #RUN 'rain1d', 'snow', 'rain5d', (ONLY N=1000)'r50'\n",
    "# for A in (1, 2, 3):\n",
    "#     for n in (100, 500, 1000, 5000, 10000, 25000, 50000):\n",
    "#         op = r\"P:\\11206883-006-dar-cloud-computing\\RhineFiles\\MET\\METmetrics\\C_AM%d\" %A + r\"_n%d\" %n  + desc + r\".pkl\"\n",
    "#         globals()[f'C_AM{A}_n{n}{extra}'] = pd.read_pickle(op)\n",
    "\n",
    "# Open 1 dataframe\n",
    "desc = 'rain5d' #'rain1d', 'snow', 'rain5d', (ONLY N=1000)'r50'\n",
    "extra = '5d' #RUN 'rain1d', 'snow', 'rain5d', (ONLY N=1000)'r50'\n",
    "n = 100 #100, 500, 1000, 5000, 10000, 25000, 50000\n",
    "for A in (1, 2, 3):\n",
    "    op = r\"P:\\11206883-006-dar-cloud-computing\\RhineFiles\\MET\\METmetrics\\C_AM%d\" %A + r\"_n%d\" %n  + desc + r\".pkl\"\n",
    "#     op = r\"P:\\11206883-006-dar-cloud-computing\\RhineFiles\\MET\\AM-Nmetrics\\C_AM%d\" %A + r\"_n%d\" %n  + desc + r\".pkl\"\n",
    "    globals()[f'C_AM{A}_n{n}{extra}'] = pd.read_pickle(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d8538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for running multiple times...   1st C0, N=100\n",
    "\n",
    "def runsAM3(AM, n, runs):\n",
    "    C_AM = pd.DataFrame(columns=['rho', 'S1avg_mean', 'S1avg_std', 'S2avg_mean', 'S2avg_std']) #, 'Savg_std', 'Savg_cv', 'gevF1_0', 'gevF1_1', 'gevF1_2', 'gevF2_0', 'gevF2_1', 'gevF2_2'])\n",
    "    for i in range(runs): #100\n",
    "        gev_fit1, gev_fit2, rho, SS1sav_mean, SS1sav_std,  SS2sav_mean, SS2sav_std = mf1.met(randSet(AM, n))\n",
    "        C_AM.loc[(i,'rho')] = rho\n",
    "        C_AM.loc[(i, 'S1avg_mean')] = SS1sav_mean\n",
    "        C_AM.loc[(i, 'S2avg_mean')] = SS2sav_mean\n",
    "        C_AM.loc[(i, 'S1avg_std')] = SS1sav_std\n",
    "        C_AM.loc[(i, 'S2avg_std')] = SS2sav_std\n",
    "\n",
    "\n",
    "    rho_mean = np.mean(C_AM.rho)\n",
    "    rho_std = np.std(C_AM.rho)\n",
    "#     rho_cv = rho_std / rho_mean\n",
    "    #S1 mean & STD\n",
    "    S1avg_mean = np.mean(C_AM.S1avg_mean)\n",
    "    S1avg_std = np.std(C_AM.S1avg_mean)\n",
    "#     S1avg_cv = S1avg_std / S1avg_mean\n",
    "    S1std_mean = np.mean(C_AM.S1avg_std)\n",
    "    S1std_std = np.std(C_AM.S1avg_std)\n",
    "    #S2 mean & STD\n",
    "    S2avg_mean = np.mean(C_AM.S2avg_mean)\n",
    "    S2avg_std = np.std(C_AM.S2avg_mean)\n",
    "#     S2avg_cv = S2avg_std / S2avg_mean\n",
    "    S2std_mean = np.mean(C_AM.S2avg_std)\n",
    "    S2std_std = np.std(C_AM.S2avg_std)\n",
    "    \n",
    "    return rho_mean, rho_std, S1avg_mean, S1avg_std, S1std_mean, S1std_std, S2avg_mean, S2avg_std, S2std_mean, S2std_std\n",
    "\n",
    "\n",
    "def runsAM3R(AM, n, runs):\n",
    "    C_AM = pd.DataFrame(columns=['rho', 'S1avg_mean', 'S1avg_std', 'S2avg_mean', 'S2avg_std']) #, 'Savg_std', 'Savg_cv', 'gevF1_0', 'gevF1_1', 'gevF1_2', 'gevF2_0', 'gevF2_1', 'gevF2_2'])\n",
    "    for i in range(runs):\n",
    "        gev_fit1, gev_fit2, rho, SS1sav_mean, SS1sav_std,  SS2sav_mean, SS2sav_std = mf1.met(randSetR(AM, n))\n",
    "        C_AM.loc[(i,'rho')] = rho\n",
    "        C_AM.loc[(i, 'S1avg_mean')] = SS1sav_mean\n",
    "        C_AM.loc[(i, 'S2avg_mean')] = SS2sav_mean\n",
    "        C_AM.loc[(i, 'S1avg_std')] = SS1sav_std\n",
    "        C_AM.loc[(i, 'S2avg_std')] = SS2sav_std\n",
    "\n",
    "    rho_mean = np.mean(C_AM.rho)\n",
    "    rho_std = np.std(C_AM.rho)\n",
    "#     rho_cv = rho_std / rho_mean\n",
    "    #S1 mean & STD\n",
    "    S1avg_mean = np.mean(C_AM.S1avg_mean)\n",
    "    S1avg_std = np.std(C_AM.S1avg_mean)\n",
    "#     S1avg_cv = S1avg_std / S1avg_mean\n",
    "    S1std_mean = np.mean(C_AM.S1avg_std)\n",
    "    S1std_std = np.std(C_AM.S1avg_std)\n",
    "    #S2 mean & STD\n",
    "    S2avg_mean = np.mean(C_AM.S2avg_mean)\n",
    "    S2avg_std = np.std(C_AM.S2avg_mean)\n",
    "#     S2avg_cv = S2avg_std / S2avg_mean\n",
    "    S2std_mean = np.mean(C_AM.S2avg_std)\n",
    "    S2std_std = np.std(C_AM.S2avg_std)\n",
    "    \n",
    "    return rho_mean, rho_std, S1avg_mean, S1avg_std, S1std_mean, S1std_std, S2avg_mean, S2avg_std, S2std_mean, S2std_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb1dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pd.read_csv('Confluences_wnames.csv', delimiter=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62271e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR n = 100, 500, 1000, 5000, 10000\n",
    "desc = 'rain' #'rain1d', 'snow', 'rain'\n",
    "extra = 'r5d'\n",
    "n = 50 #100, 500, 1000, 5000, 10000\n",
    "runs = 100 # 100 (n=100, 500, 1000), 50 (n=1000, 5000, 10000)\n",
    "\n",
    "for c in range(0, len(conf)): #len(conf)\n",
    "    print(f'Starting {c} at {str(datetime.now().time())}')\n",
    "    op = r\"P:\\11206883-006-dar-cloud-computing\\RhineFiles\\MET\\AMmet\\C%d_\" %c + desc + r\"_\" \n",
    "    AM1 = pd.read_pickle(op + \"AM1.pkl\")\n",
    "    AM2 = pd.read_pickle(op + \"AM2.pkl\")\n",
    "    AM3 = pd.read_pickle(op + \"AM3.pkl\")\n",
    "    for A in ('AM1', 'AM2', 'AM3'): #'AM1', \n",
    "        rho_mean, rho_std, S1avg_mean, S1avg_std, S1std_mean, S1std_std, S2avg_mean, S2avg_std, S2std_mean, S2std_std = runsAM3(globals()[f'{A}'], n, runs)\n",
    "        globals()[f'C_{A}_n{n}{extra}'].loc[(c,'rho_mean')] = rho_mean\n",
    "        globals()[f'C_{A}_n{n}{extra}'].loc[(c,'rho_std')] = rho_std\n",
    "#         globals()[f'C_{A}_n{n}'].loc[(c,'rho_cv')] = rho_cv\n",
    "        globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S1avg_mean')] = S1avg_mean\n",
    "        globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S1avg_std')] = S1avg_std\n",
    "        globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S1std_mean')] = S1std_mean\n",
    "        globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S1std_std')] = S1std_std\n",
    "#         globals()[f'C_{A}_n{n}'].loc[(c,'S1avg_cv')] = S1avg_cv\n",
    "        globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S2avg_mean')] = S2avg_mean\n",
    "        globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S2avg_std')] = S2avg_std\n",
    "        globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S2std_mean')] = S2std_mean\n",
    "        globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S2std_std')] = S2std_std\n",
    "#         globals()[f'C_{A}_n{n}'].loc[(c,'S2avg_cv')] = S2avg_cv\n",
    "        print(f'Done C{A}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1d1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 1 dataframe\n",
    "desc = 'rain5d' #'rain1d', 'snow', 'rain5d', (ONLY N=1000)'r50'\n",
    "extra = 'r5d' #RUN 'rain1d', 'snow', 'rain5d', (ONLY N=1000)'r50'\n",
    "n = 50 #100, 500, 1000, 5000, 10000, 25000, 50000\n",
    "for A in (1, 2, 3):\n",
    "#     sv = r\"P:\\11206883-006-dar-cloud-computing\\RhineFiles\\MET\\AM-Nmetrics\\C_AM%d\" %A + r\"_n%d\" %n  + desc + r\".pkl\"\n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\RhineFiles\\MET\\METmetrics2\\N%d\" %n + r\"_AM%d_\" %A + desc + r\".pkl\"\n",
    "    globals()[f'C_AM{A}_n{n}{extra}'].to_pickle(sv)    \n",
    "    print(f'Saved {A}_n{n} at {str(datetime.now().time())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2dc41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR n = 25000\n",
    "desc = '' #'rain1d', 'snow', 'rain'\n",
    "extra = ''\n",
    "n = 25000\n",
    "runs = 10\n",
    "\n",
    "for c in range(0, len(conf)): #len(conf)\n",
    "    print(f'Starting {c}')\n",
    "    op = r\"P:\\11206883-006-dar-cloud-computing\\RhineFiles\\MET\\AMmet\\C%d_\" %c + desc + r\"_\" \n",
    "    AM1 = pd.read_pickle(op + \"AM1.pkl\")\n",
    "    AM2 = pd.read_pickle(op + \"AM2.pkl\")\n",
    "    AM3 = pd.read_pickle(op + \"AM3.pkl\")\n",
    "    for A in ('AM1', 'AM2', 'AM3'):\n",
    "        for a in (AM1, AM2, AM3):\n",
    "            rho_mean, rho_std, S1avg_mean, S1avg_std, S1std_mean, S1std_std, S2avg_mean, S2avg_std, S2std_mean, S2std_std = runsAM3R(a, n, runs)\n",
    "            globals()[f'C_{A}_n{n}{extra}'].loc[(c,'rho_mean')] = rho_mean\n",
    "            globals()[f'C_{A}_n{n}{extra}'].loc[(c,'rho_std')] = rho_std\n",
    "    #         globals()[f'C_{A}_n{n}'].loc[(c,'rho_cv')] = rho_cv\n",
    "            globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S1avg_mean')] = S1avg_mean\n",
    "            globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S1avg_std')] = S1avg_std\n",
    "            globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S1std_mean')] = S1std_mean\n",
    "            globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S1std_std')] = S1std_std\n",
    "    #         globals()[f'C_{A}_n{n}'].loc[(c,'S1avg_cv')] = S1avg_cv\n",
    "            globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S2avg_mean')] = S2avg_mean\n",
    "            globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S2avg_std')] = S2avg_std\n",
    "            globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S2std_mean')] = S2std_mean\n",
    "            globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S2std_std')] = S2std_std\n",
    "    #         globals()[f'C_{A}_n{n}'].loc[(c,'S2avg_cv')] = S2avg_cv\n",
    "    print(f'Done C{c}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bca6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FOR n = 50000\n",
    "desc = '' #'rain1d', 'snow', 'rain'\n",
    "extra = ''\n",
    "n = 50000\n",
    "runs = 10\n",
    "A = 'AM1' # 'AM1','AM2', 'AM3'\n",
    "\n",
    "\n",
    "for c in range(0, len(conf)): #len(conf)\n",
    "    n=50000 #Full data\n",
    "    print(f'Starting {c}')\n",
    "    op = r\"P:\\11206883-006-dar-cloud-computing\\RhineFiles\\MET\\AMmet\\C%d_\" %c + desc + r\"_\" \n",
    "    AM1 = pd.read_pickle(op + \"AM1.pkl\")\n",
    "    AM2 = pd.read_pickle(op + \"AM2.pkl\")\n",
    "    AM3 = pd.read_pickle(op + \"AM3.pkl\")\n",
    "\n",
    "    gev_fit1, gev_fit2, rho, S1avg_mean, S1std_mean,  S2avg_mean, S2std_mean = mf1.met(AM3) #\n",
    "    globals()[f'C_{A}_n{n}{extra}'].loc[(c,'rho_mean')] = rho\n",
    "    globals()[f'C_{A}_n{n}{extra}'].loc[(c,'rho_std')] = 0\n",
    "#         globals()[f'C_{A}_n{n}'].loc[(c,'rho_cv')] = rho_cv\n",
    "    globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S1avg_mean')] = S1avg_mean\n",
    "    globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S1avg_std')] = 0\n",
    "    globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S1std_mean')] = S1std_mean\n",
    "    globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S1std_std')] = 0\n",
    "#         globals()[f'C_{A}_n{n}'].loc[(c,'S1avg_cv')] = S1avg_cv\n",
    "    globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S2avg_mean')] = S2avg_mean\n",
    "    globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S2avg_std')] = 0\n",
    "    globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S2std_mean')] = S2std_mean\n",
    "    globals()[f'C_{A}_n{n}{extra}'].loc[(c,'S2std_std')] = 0\n",
    "\n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dar-cloud')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "dba0fec6c0a5dc3650c48ce5794cc777babb314a0f31f50d55fe76ea6fe6645b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

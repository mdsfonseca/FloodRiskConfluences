{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import HidFunctions as hf \n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import norm\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb399d05",
   "metadata": {},
   "source": [
    "Open the 50000 AM peak files\n",
    "\n",
    "Random selection according to N, pero set of AM\n",
    "\n",
    "Calculate the metrics per confluence (100 runs pero sample)  and stores them according to the confluences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f747ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for running multiple times...   1st C0, N=100\n",
    "\n",
    "def runsAM3(AM, n, runs):\n",
    "    C_AM = pd.DataFrame(columns=['rho', 'S1avg_mean', 'S1avg_std', 'S2avg_mean', 'S2avg_std']) #, 'Savg_std', 'Savg_cv', 'gevF1_0', 'gevF1_1', 'gevF1_2', 'gevF2_0', 'gevF2_1', 'gevF2_2'])\n",
    "    for i in range(runs): #100\n",
    "        gev_fit1, gev_fit2, rho, SS1sav_mean, SS1sav_std,  SS2sav_mean, SS2sav_std = met(hf.randSet(AM, n))\n",
    "        C_AM.loc[(i,'rho')] = rho\n",
    "        C_AM.loc[(i, 'S1avg_mean')] = SS1sav_mean\n",
    "        C_AM.loc[(i, 'S2avg_mean')] = SS2sav_mean\n",
    "        C_AM.loc[(i, 'S1avg_std')] = SS1sav_std\n",
    "        C_AM.loc[(i, 'S2avg_std')] = SS2sav_std\n",
    "\n",
    "\n",
    "    rho_mean = np.mean(C_AM.rho)\n",
    "    rho_std = np.std(C_AM.rho)\n",
    "#     rho_cv = rho_std / rho_mean\n",
    "    #S1 mean & STD\n",
    "    S1avg_mean = np.mean(C_AM.S1avg_mean)\n",
    "    S1avg_std = np.std(C_AM.S1avg_mean)\n",
    "#     S1avg_cv = S1avg_std / S1avg_mean\n",
    "    S1std_mean = np.mean(C_AM.S1avg_std)\n",
    "    S1std_std = np.std(C_AM.S1avg_std)\n",
    "    #S2 mean & STD\n",
    "    S2avg_mean = np.mean(C_AM.S2avg_mean)\n",
    "    S2avg_std = np.std(C_AM.S2avg_mean)\n",
    "#     S2avg_cv = S2avg_std / S2avg_mean\n",
    "    S2std_mean = np.mean(C_AM.S2avg_std)\n",
    "    S2std_std = np.std(C_AM.S2avg_std)\n",
    "    \n",
    "    return rho_mean, rho_std, S1avg_mean, S1avg_std, S1std_mean, S1std_std, S2avg_mean, S2avg_std, S2std_mean, S2std_std\n",
    "\n",
    "def dfN():\n",
    "    conf_AM = pd.read_csv(r\"Confluences_ok2.csv\", delimiter=';')\n",
    "    conf_AM['rho_mean'] = ''\n",
    "    conf_AM['rho_std'] = ''\n",
    "#     conf_AM['rho_cv'] = ''\n",
    "    conf_AM['S1avg_mean'] = ''\n",
    "    conf_AM['S1avg_std'] = ''\n",
    "    conf_AM['S1std_mean'] = ''\n",
    "    conf_AM['S1std_std'] = ''\n",
    "#     conf_AM['S1avg_cv'] = ''\n",
    "    conf_AM['S2avg_mean'] = ''\n",
    "    conf_AM['S2avg_std'] = ''\n",
    "    conf_AM['S2std_mean'] = ''\n",
    "    conf_AM['S2std_std'] = ''\n",
    "#     conf_AM['S2avg_cv'] = ''\n",
    "    return conf_AM\n",
    "\n",
    "def met(am):\n",
    "    gev_fit1, gev_fit2, rho = hf.marginalsAM('Q_S1', 'Q_S2', am)\n",
    "    SS1sav_mean = np.mean(am['S1/S1savg'])\n",
    "    SS1sav_std = np.std(am['S1/S1savg'])\n",
    "    SS2sav_mean = np.mean(am['S2/S2savg'])\n",
    "    SS2sav_std = np.std(am['S2/S2savg'])\n",
    "    \n",
    "    return gev_fit1, gev_fit2, rho, SS1sav_mean, SS1sav_std, SS2sav_mean, SS2sav_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca40f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ALL the dataframes per AM set, per N-sample size\n",
    "# extra = 'd1d' #5d, 1d\n",
    "# for A in ('AM1', 'AM2', 'AM3'):\n",
    "#     for n in ('5000', '10000', '25000', '50000'): # 100', '500', '1000', \n",
    "#         globals()[f'C_{A}_n{n}{extra}'] = dfN()\n",
    "\n",
    "# Create 1 w/extra info  N=100 r=50\n",
    "extra = 'd1d' #RUN 'd1d', 'd5d'\n",
    "n = 50000 #20, 50, 100, 500, 1000, 5000, 10000, 25000, 50000\n",
    "for A in (1, 2, 3): #'AM1', \n",
    "#     globals()[f'C_{A}_n{n}{extra}'] = hf.dfN()\n",
    "    globals()[f'N{n}_AM{A}_{extra}'] = dfN()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ac9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ALL the dataframes\n",
    "# desc = 'disc1d' #SAVE'disc1d', 'disc5d'\n",
    "# extra = '1d' #RUN '1d', '5d'\n",
    "# for A in (1, 2, 3):\n",
    "#     for n in (100, 500, 1000): #, 5000, 10000, 25000, 50000\n",
    "#         sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HID\\HIDmetrics\\C_AM%d\" %A + r\"_n%d\" %n  + desc + r\".pkl\"\n",
    "#         globals()[f'C_AM{A}_n{n}{extra}'].to_pickle(sv)\n",
    "\n",
    "# Save 1 dataframe\n",
    "desc = 'disc1d' #OPEN 'disc1d', 'disc5d'\n",
    "extra = 'd1d' #RUN 'd1d', 'd5d'\n",
    "n = 50000 #100, 500, 1000, 5000, 10000, 25000, 50000\n",
    "for A in (1, 2, 3): #1, \n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HIDnew\\04_HYDmetrics\\N%d\" %n + r\"_AM%d_\" %A + desc + r\".pkl\"\n",
    "    globals()[f'N{n}_AM{A}_{extra}'].to_pickle(sv)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae082afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open ALL the dataframes\n",
    "# desc = '' #OPEN 'disc1d', 'disc5d'\n",
    "# extra = '' #RUN '1d', '5d'\n",
    "# for A in (1, 2, 3):\n",
    "#     for n in (100, 500, 1000, 5000, 10000, 25000, 50000):\n",
    "#         op = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HID\\HIDmetrics\\C_AM%d\" %A + r\"_n%d\" %n  + desc + r\".pkl\"\n",
    "#         globals()[f'C_AM{A}_n{n}{extra}'] = pd.read_pickle(op)\n",
    "\n",
    "# Open 1 dataframe\n",
    "desc = 'disc1d' #OPEN 'disc1d', 'disc5d'\n",
    "extra = 'd1d' #RUN 'd1d', 'd5d'\n",
    "n = 10000 #100, 500, 1000, 5000, 10000, 25000, 50000\n",
    "for A in (1, 2, 3):\n",
    "    op = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HIDnew\\04_HYDmetrics\\N%d\" %n + r\"_AM%d_\" %A + desc + r\".pkl\"\n",
    "    globals()[f'N{n}_AM{A}_{extra}'] = pd.read_pickle(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04af717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pd.read_csv(r\"Confluences_ok2.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f3648",
   "metadata": {},
   "source": [
    "### FULL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afbbc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc = 'disc1d' #OPEN 'disc1d', 'disc5d'\n",
    "extra = 'd1d' #RUN 'd1d', 'd5d'\n",
    "n = 50000\n",
    "runs = 1\n",
    "# A = 3 # 'AM1','AM2', 'AM3'\n",
    "\n",
    "print(f'Starting at {str(datetime.now())}')\n",
    "\n",
    "for c in range(0, len(conf)): #len(conf)\n",
    "    n=50000 #Full data\n",
    "    print(f'Starting {c} at {str(datetime.now().time())}')\n",
    "    op = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HIDnew\\03_AMhyd\" + r\"\\disc1d_\" + conf.Conf[c]\n",
    "    for A in ('AM1', 'AM2', 'AM3'):\n",
    "        AM = pd.read_pickle(op + r\"_\" + A + \".pkl\")\n",
    "\n",
    "        gev_fit1, gev_fit2, rho, S1avg_mean, S1std_mean,  S2avg_mean, S2std_mean = met(AM) #CHANGE\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'rho_mean')] = rho\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'rho_std')] = 0\n",
    "    #         globals()[f'N{n}_AM{A}_{extra}'].loc[(c,'rho_cv')] = rho_cv\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S1avg_mean')] = S1avg_mean\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S1avg_std')] = 0\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S1std_mean')] = S1std_mean\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S1std_std')] = 0\n",
    "    #         globals()[f'N{n}_AM{A}_{extra}'].loc[(c,'S1avg_cv')] = S1avg_cv\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S2avg_mean')] = S2avg_mean\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S2avg_std')] = 0\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S2std_mean')] = S2std_mean\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S2std_std')] = 0\n",
    "        print(f'Done {A} at {str(datetime.now().time())}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 1 dataframe\n",
    "desc = 'disc1d' #OPEN 'disc1d', 'disc5d'\n",
    "extra = 'd1d' #RUN 'd1d', 'd5d'\n",
    "n = 50000 #100, 500, 1000, 5000, 10000, 25000, 50000\n",
    "for A in (1, 2, 3): #1, \n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HIDnew\\04_HYDmetrics\\N%d\" %n + r\"_AM%d_\" %A + desc + r\".pkl\"\n",
    "    globals()[f'N{n}_AM{A}_{extra}'].to_pickle(sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc5f38",
   "metadata": {},
   "source": [
    "### 20, 50, 100, 500, 1000, 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ALL the dataframes per AM set, per N-sample size\n",
    "extra = 'd1d_R50' #5d, 1d\n",
    "for A in ('AM1', 'AM2', 'AM3'):\n",
    "    n=1000\n",
    "#     for n in ('1000'): #'20', '50', '100', '500', , '5000'\n",
    "    globals()[f'N{n}_{A}_{extra}'] = dfN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653adb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc = 'disc1d' #OPEN 'disc1d', 'disc5d'\n",
    "extra = 'd1d' #RUN '1d', '5d'\n",
    "n = 5000  #100, 500, 1000, 5000, 10000\n",
    "runs = 50  # 100 (n=100, 500, 1000), 50 (n=1000, 5000, 10000)\n",
    "\n",
    "for c in range(0, len(conf)): #len(conf)\n",
    "    print(f'Starting {conf.Conf[c]} at {str(datetime.now())}')\n",
    "    op = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HIDnew\\03_AMhyd\" + r\"\\disc1d_\" + conf.Conf[c]\n",
    "    AM1 = pd.read_pickle(op + \"_AM1.pkl\")\n",
    "    AM2 = pd.read_pickle(op + \"_AM2.pkl\")\n",
    "    AM3 = pd.read_pickle(op + \"_AM3.pkl\")\n",
    "    for A in ('AM1', 'AM2', 'AM3'): # \n",
    "        rho_mean, rho_std, S1avg_mean, S1avg_std, S1std_mean, S1std_std, S2avg_mean, S2avg_std, S2std_mean, S2std_std = runsAM3(globals()[f'{A}'], n, runs)\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'rho_mean')] = rho_mean\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'rho_std')] = rho_std\n",
    "#         globals()[f'N{n}_AM{A}_{extra}'].loc[(c,'rho_cv')] = rho_cv\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S1avg_mean')] = S1avg_mean\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S1avg_std')] = S1avg_std\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S1std_mean')] = S1std_mean\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S1std_std')] = S1std_std\n",
    "#         globals()[f'N{n}_AM{A}_{extra}'].loc[(c,'S1avg_cv')] = S1avg_cv\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S2avg_mean')] = S2avg_mean\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S2avg_std')] = S2avg_std\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S2std_mean')] = S2std_mean\n",
    "        globals()[f'N{n}_{A}_{extra}'].loc[(c,'S2std_std')] = S2std_std\n",
    "#         globals()[f'N{n}_AM{A}_{extra}'].loc[(c,'S2avg_cv')] = S2avg_cv\n",
    "        print(f'Done {A}')\n",
    "print(f'Done at {str(datetime.now().time())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 1 dataframe\n",
    "desc = 'disc1d' #OPEN 'disc1d', 'disc5d'\n",
    "extra = 'd1d' #RUN 'd1d', 'd5d'\n",
    "n = 5000 #100, 500, 1000, 5000, 10000, 25000, 50000\n",
    "for A in (1, 2, 3): #1, \n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HIDnew\\04_HYDmetrics\\N%d\" %n + r\"_AM%d_\" %A + desc + r\".pkl\"\n",
    "    globals()[f'N{n}_AM{A}_{extra}'].to_pickle(sv)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b29cc",
   "metadata": {},
   "source": [
    "## Exploring the data per confluence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833cb687",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "op = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HIDnew\\03_AMhyd\" + r\"\\disc1d_\" + conf.Conf[c]\n",
    "AM1 = pd.read_pickle(op + r\"_AM1.pkl\")\n",
    "AM2 = pd.read_pickle(op + r\"_AM2.pkl\")\n",
    "AM3 = pd.read_pickle(op + r\"_AM3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340754df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho1, Sp = spearmanr(AM1['Q_S1'], AM1['Q_S2'])\n",
    "rho2, Sp = spearmanr(AM2['Q_S1'], AM2['Q_S2'])\n",
    "rho3, Sp = spearmanr(AM3['Q_S1'], AM3['Q_S2'])\n",
    "rho1, rho2, rho3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "color='blue'\n",
    "start = 1000\n",
    "end = 1050\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(AM1['Q_S1'][start:end], AM1['Q_S2'][start:end], 'o', color='none', markeredgecolor=color,markersize=10, label='Set 1: S1max-S2conc')\n",
    "plt.plot(AM2['Q_S1'][start:end], AM2['Q_S2'][start:end], 'x', color=color, markersize=9, label='Set 2: S2max-S1conc')\n",
    "plt.plot(AM3['Q_S1'][start:end], AM3['Q_S2'][start:end], '.', color=color, markersize=10, label='Set 3: Cmax (C=S1+S2)')\n",
    "# plt.title(f'{td} | C{c+1} ({peaks} peaks AM)', fontsize=20, y=1.05)\n",
    "# plt.xlabel(f'S1 ({unit})', fontsize=18)\n",
    "# plt.ylabel(f'S2 ({unit})', fontsize=18)\n",
    "plt.xlim(left=0, right=1500)\n",
    "plt.ylim(ymin = 0, ymax =1500)\n",
    "plt.xticks(fontsize=12, rotation=90)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=18, bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2ac6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

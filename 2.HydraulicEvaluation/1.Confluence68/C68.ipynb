{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04fa368",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7374a",
   "metadata": {},
   "source": [
    "Exploration of the time series of Confluence 68:\n",
    "\n",
    "Annual maxima sets starting the block maxima the 1st of january\n",
    "\n",
    "Annual maxima sets starting the block maxima in the dry season\n",
    "\n",
    "Time series of the minimum and maximun peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See MetFunctions AM\n",
    "def AM(conf_):\n",
    "    \"\"\"\n",
    "    Annual Maxima sets\n",
    "    ds: dictionary with all the Time series per station \n",
    "    conf: configuration of the confluences\n",
    "    c: confluence to be analyzed\n",
    "    w: window of the multi-day events\n",
    "    Returns: ds_\n",
    "    \"\"\"\n",
    "    #create the Pandas DataFrame\n",
    "#     conf_ = pd.DataFrame(columns=['year', 'month', 'day', 'P_S1', 'P_S2'])\n",
    "#     conf_['Q_S1'] = ds[conf.HVB_Q1[c]]\n",
    "#     conf_['Q_S2'] = ds[conf.HVB_Q2[c]]\n",
    "#     conf_['year'] = ds['YEAR']\n",
    "#     conf_['month'] = ds['MONTH']\n",
    "#     conf_['day'] = ds['DAY']\n",
    "    \n",
    "    #Delete the rows with values lower than 0:\n",
    "    conf_1 = conf_[~(conf_['Q_S1'] <= 0)]   \n",
    "    conf_1 = conf_[~(conf_['Q_S2'] <= 0)]   \n",
    "#     conf_1['P_S1'].loc[0] = 0      --> before I was just making the 1st value = to 0\n",
    "#     conf_1['P_S2'].loc[0] = 0\n",
    "    \n",
    "    #1 Rolling 5 days\n",
    "#     if w == 5:  #Check if this makes sense..  \n",
    "#         conf_1['P_S1rol'] = conf_1['P_S1'].rolling(window=w).mean()\n",
    "#         conf_1['P_S2rol'] = conf_1['P_S2'].rolling(window=w).mean()\n",
    "#         conf_1['Conf'] = conf_1.P_S1rol + conf_1.P_S2rol\n",
    "#     elif w == 1:\n",
    "#     conf_1['P_S1rol'] = conf_1['Q_S1']\n",
    "#     conf_1['P_S2rol'] = conf_1['Q_S2']\n",
    "    conf_1['Conf'] = conf_1.Q_S1 + conf_1.Q_S2\n",
    "    \n",
    "    #2 Extreme selection sets\n",
    "#     conf_1.index = conf_1.index.astype(int)\n",
    "#     conf_1['Time'] = pd.to_datetime(conf_1.index, unit='d')\n",
    "#     conf_1['year']=conf_1.Time.dt.year\n",
    "#     conf_1['month']=conf_1.Time.dt.month\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Seasonal averages\n",
    "    conditions = [\n",
    "        (conf_1.month==1)|(conf_1.month==2)|(conf_1.month==12),\n",
    "        (conf_1.month==3)|(conf_1.month==4)|(conf_1.month==5),\n",
    "        (conf_1.month==6)|(conf_1.month==7)|(conf_1.month==8),\n",
    "        (conf_1.month==9)|(conf_1.month==10)|(conf_1.month==11)]\n",
    "\n",
    "    choices = ['DJF', 'MAM', 'JJA', 'SON']\n",
    "    conf_1['season'] = np.select(conditions, choices, default='ERROR')\n",
    "    \n",
    "    savg_S1 = conf_1.groupby(['season'])['Q_S1'].mean()\n",
    "    savg_S2 = conf_1.groupby(['season'])['Q_S2'].mean()\n",
    "    savg_C = conf_1.groupby(['season'])['Conf'].mean()\n",
    "\n",
    "    \n",
    "    numyears = conf_1.year.iloc[-1] - conf_1.year.iloc[0] + 1\n",
    "    firstyear = conf_1.year.iloc[0]\n",
    "\n",
    "\n",
    "    am1 = pd.DataFrame() #columns=['Time', 'year', 'AccumP_rol0', 'AccumP_rol1']\n",
    "    am2 = pd.DataFrame()\n",
    "    am3 = pd.DataFrame()\n",
    "    for i in range(numyears):\n",
    "        am1 = am1.append(conf_1.loc[conf_1.Q_S1[conf_1.year == firstyear + i].idxmax()])#, ignore_index=True)\n",
    "        am2 = am2.append(conf_1.loc[conf_1.Q_S2[conf_1.year == firstyear + i].idxmax()])\n",
    "        am3 = am3.append(conf_1.loc[conf_1.Conf[conf_1.year == firstyear + i].idxmax()])        \n",
    "\n",
    "    return am1, am2, am3, savg_S1, savg_S2, savg_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848dc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pd.read_csv(r\"C:\\Users\\Fonse_ma\\OneDrive - Stichting Deltares\\Desktop\\Maria\\Notebooks\\HBV\\Confluences_ok2.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2090fb",
   "metadata": {},
   "source": [
    "## HID_02\n",
    "### AM files & Savg\n",
    "2000 peaks per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a3b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0, 25):\n",
    "    conf_ = pd.read_csv(r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\C68_TS\\C68_TS%d.csv\" %j, delimiter=';')\n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\C68_AM\\C68_AM%d_\" %j\n",
    "    am1_, am2_, am3_, savg_S1_, savg_S2_, savg_C_ = AM(conf_)\n",
    "    am1_.to_pickle(sv + \"AM1.pkl\")\n",
    "    am2_.to_pickle(sv + \"AM2.pkl\")\n",
    "    am3_.to_pickle(sv + \"AM3.pkl\")\n",
    "    savg_S1_.to_pickle(sv + \"savg_S1.pkl\")\n",
    "    savg_S2_.to_pickle(sv + \"savg_S2.pkl\")\n",
    "    savg_C_.to_pickle(sv + \"savg_C.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE NEW FILES FROM 01_TSfiles\n",
    "TS = pd.DataFrame()\n",
    "for j in range(0, 25):\n",
    "    conf_ = pd.read_csv(r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HIDnew\\01_TSfiles\\TS%d_C68.csv\" %j, delimiter=';')\n",
    "    TS = pd.concat([TS, conf_])\n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HIDnew\\01_TSonefile\"\n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\C68_AM\\C68_AM%d_\" %j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46b33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "        (TS.month==1)|(TS.month==2)|(TS.month==3)|(TS.month==4)|(TS.month==5)|(TS.month==6)|(TS.month==7)|(TS.month==8),\n",
    "        (TS.month==9)|(TS.month==10)|(TS.month==11)|(TS.month==12)]\n",
    "\n",
    "choices = [TS['year'], TS['year'] + 1]\n",
    "TS['yearAM'] = np.select(conditions, choices, default='ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee989f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_ = TS[~(TS['Q_S1'] < 0)]\n",
    "TS_ = TS[~(TS['Q_S2'] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74855cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_['Q_C'] = TS_['Q_S1'] + TS_['Q_S2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d274dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_.index = np.arange(len(TS_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8affe58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AM1_try = TS_.groupby(['yearAM'])['Q_S1'].idxmax()\n",
    "AM2_try = TS_.groupby(['yearAM'])['Q_S2'].idxmax()\n",
    "AM3_try = TS_.groupby(['yearAM'])['Q_C'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e95c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "am1 = pd.DataFrame() #columns=['Time', 'year', 'AccumP_rol0', 'AccumP_rol1']\n",
    "am2 = pd.DataFrame()\n",
    "am3 = pd.DataFrame()\n",
    "for i in range(0, 10000): #len(AM1_try)\n",
    "    am1 = am1.append(TS_.loc[AM1_try[i]])#, ignore_index=True)\n",
    "    am2 = am2.append(TS_.loc[AM2_try[i]])\n",
    "    am3 = am3.append(TS_.loc[AM3_try[i]])\n",
    "    \n",
    "# for i in range(len(AM1_try)): #len(AM1_try)\n",
    "#     am1 = am1.append(TS_.loc[AM1_try[i]])#, ignore_index=True)\n",
    "#     am2 = am2.append(TS_.loc[AM2_try[i]])\n",
    "#     am3 = am3.append(TS_.loc[AM3_try[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000, 20000): #len(AM1_try)\n",
    "    am1 = am1.append(TS_.loc[AM1_try[i]])#, ignore_index=True)\n",
    "    am2 = am2.append(TS_.loc[AM2_try[i]])\n",
    "    am3 = am3.append(TS_.loc[AM3_try[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AM1_try['ID'] = TS_.groupby(['yearAM'])['Q_S1'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "am1_, am2_, am3_, savg_S1_, savg_S2_, savg_C_ = AM(TS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02308e9a",
   "metadata": {},
   "source": [
    "## HID_03\n",
    "### 1 file of AM\n",
    "Only from 5 to 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aaad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddSavg(am1, S1_savg, S2_savg, C_savg):\n",
    "    conditionsALL = [am1.season=='DJF', am1.season=='JJA', am1.season=='MAM', am1.season=='SON']\n",
    "\n",
    "    choicesS1 = [S1_savg['DJF'], S1_savg['JJA'], S1_savg['MAM'], S1_savg['SON']]\n",
    "    choicesS2 = [S2_savg['DJF'], S2_savg['JJA'], S2_savg['MAM'], S2_savg['SON']]\n",
    "    choicesC = [C_savg['DJF'], C_savg['JJA'], C_savg['MAM'], C_savg['SON']]\n",
    "\n",
    "    am1['S1savg'] = np.select(conditionsALL, choicesS1, default='ERROR').astype(float)\n",
    "    am1['S2savg'] = np.select(conditionsALL, choicesS2, default='ERROR').astype(float)\n",
    "    am1['Csavg'] = np.select(conditionsALL, choicesC, default='ERROR').astype(float)\n",
    "    am1['S1/S1savg'] = am1.Q_S1 / am1.S1savg\n",
    "    am1['S2/S2savg'] = am1.Q_S2 / am1.S2savg\n",
    "    am1['C/Csavg'] = am1.Conf / am1.Csavg\n",
    "    return am1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "am1 = pd.DataFrame()\n",
    "am2 = pd.DataFrame()\n",
    "am3 = pd.DataFrame()\n",
    "savg_S1 = 0\n",
    "savg_S2 = 0\n",
    "savg_C = 0\n",
    "\n",
    "\n",
    "sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\C68_40000peaks\\C68_\" \n",
    "# C68_40000peaks\n",
    "\n",
    "for j in range(5, 25):  # 0, 25 \n",
    "    op = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\C68_AM\\C68_AM%d_\" %j\n",
    "#     op =  r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HIDnew\\02_AMdisc%d\" %w + r\"d\\C%d_\" %c + r\"%d_\" %j \n",
    "#     op =  r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HID\\AMdisc%d\" %w + r\"d\\C%d_\" %c + r\"%d_\" %j \n",
    "    am1_ = pd.read_pickle(op + \"AM1.pkl\")\n",
    "    am2_ = pd.read_pickle(op + \"AM2.pkl\")\n",
    "    am3_ = pd.read_pickle(op + \"AM3.pkl\")\n",
    "    savg_S1_ = pd.read_pickle(op + \"savg_S1.pkl\")\n",
    "    savg_S2_ = pd.read_pickle(op + \"savg_S2.pkl\")\n",
    "    savg_C_ = pd.read_pickle(op + \"savg_C.pkl\")\n",
    "    am1 = pd.concat([am1, am1_])\n",
    "    am2 = pd.concat([am2, am2_])\n",
    "    am3 = pd.concat([am3, am3_])\n",
    "    savg_S1 += savg_S1_\n",
    "    savg_S2 += savg_S2_\n",
    "    savg_C += savg_C_\n",
    "    count += 1\n",
    "#from all the loops, get am1, am2, am3, savg_S1, savg_S2, savg_C combinado de los 50,000 anos\n",
    "S1_savg = savg_S1 / count\n",
    "S2_savg = savg_S2 / count\n",
    "C_savg = savg_C / count\n",
    "\n",
    "AM1 = AddSavg(am1, S1_savg, S2_savg, C_savg)\n",
    "AM2 = AddSavg(am2, S1_savg, S2_savg, C_savg)\n",
    "AM3 = AddSavg(am3, S1_savg, S2_savg, C_savg)\n",
    "#     now we want to save the 3 data frames per confluence\n",
    "AM1.to_pickle(sv + \"AM1.pkl\")\n",
    "AM2.to_pickle(sv + \"AM2.pkl\")\n",
    "AM3.to_pickle(sv + \"AM3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa920bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSsets(AM1, AM2, AM3, c, td, unit, peaks, color):\n",
    "#     AM1 = pd.read_pickle(op + \"AM1.pkl\")\n",
    "#     AM2 = pd.read_pickle(op + \"AM2.pkl\")\n",
    "#     AM3 = pd.read_pickle(op + \"AM3.pkl\")\n",
    "    \n",
    "    AM1['ind'] = np.arange(len(AM1))\n",
    "    AM2['ind'] = np.arange(len(AM2))\n",
    "    AM3['ind'] = np.arange(len(AM3))\n",
    "    randomindex1 = np.random.choice(AM1.ind, size=peaks, replace=False)\n",
    "    set1 = pd.DataFrame()\n",
    "    set2 = pd.DataFrame()\n",
    "    set3 = pd.DataFrame()\n",
    "    for i in range(peaks):\n",
    "        set1 = set1.append(AM1.loc[AM1.ind == randomindex1[i]])\n",
    "        set2 = set2.append(AM2.loc[AM2.ind == randomindex1[i]])\n",
    "        set3 = set3.append(AM3.loc[AM3.ind == randomindex1[i]])\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot(set1['Q_S1'], set1['Q_S2'], 'o', color='none', markeredgecolor=color,markersize=10, label='Set 1: S1max-S2conc')\n",
    "    plt.plot(set2['Q_S1'], set2['Q_S2'], 'x', color=color, markersize=9, label='Set 2: S2max-S1conc')\n",
    "    plt.plot(set3['Q_S1'], set3['Q_S2'], '.', color=color, markersize=10, label='Set 3: Cmax (C=S1+S2)')\n",
    "    plt.title(f'{td} | C{c+1} ({peaks} peaks AM)', fontsize=20, y=1.05)\n",
    "    plt.xlabel(f'S1 ({unit})', fontsize=18)\n",
    "    plt.ylabel(f'S2 ({unit})', fontsize=18)\n",
    "    plt.xlim(left=0, right=16000)\n",
    "    plt.ylim(ymin = 0, ymax =4000)\n",
    "    plt.xticks(fontsize=12, rotation=90)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(fontsize=18, bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "\n",
    "    plt.grid()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ea56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "color='blue'\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(AM1['Q_S1'], AM1['Q_S2'], 'o', color='none', markeredgecolor=color,markersize=10, label='Set 1: S1max-S2conc')\n",
    "plt.plot(AM2['Q_S1'], AM2['Q_S2'], 'x', color=color, markersize=9, label='Set 2: S2max-S1conc')\n",
    "plt.plot(AM3['Q_S1'], AM3['Q_S2'], '.', color=color, markersize=10, label='Set 3: Cmax (C=S1+S2)')\n",
    "# plt.title(f'{td} | C{c+1} ({peaks} peaks AM)', fontsize=20, y=1.05)\n",
    "# plt.xlabel(f'S1 ({unit})', fontsize=18)\n",
    "# plt.ylabel(f'S2 ({unit})', fontsize=18)\n",
    "plt.xlim(left=0, right=10000)\n",
    "plt.ylim(ymin = 0, ymax =5000)\n",
    "plt.xticks(fontsize=12, rotation=90)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=18, bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e944c",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac8f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\C68_40000peaks\\C68_\" \n",
    "AM1 = pd.read_pickle(op + \"AM1.pkl\")\n",
    "AM2 = pd.read_pickle(op + \"AM2.pkl\")\n",
    "AM3 = pd.read_pickle(op + \"AM3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053771a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AM1.index = np.arange(len(AM1))\n",
    "AM2.index = np.arange(len(AM2))\n",
    "AM3.index = np.arange(len(AM3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb1303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho1, Sp1 = spearmanr(AM1['Q_S1'], AM1['Q_S2'])\n",
    "rho2, Sp2 = spearmanr(AM2['Q_S1'], AM2['Q_S2'])\n",
    "rho3, Sp3 = spearmanr(AM3['Q_S1'], AM3['Q_S2'])\n",
    "print(f'AM1_rho={rho1:.4}, AM2_rho={rho2:.4}, AM3_rho={rho3:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a736790",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho1, Sp1 = spearmanr(am1_['Q_S1'], am1_['Q_S2'])\n",
    "rho2, Sp2 = spearmanr(am2_['Q_S1'], am2_['Q_S2'])\n",
    "rho3, Sp3 = spearmanr(am3_['Q_S1'], am3_['Q_S2'])\n",
    "print(f'AM1_rho={rho1:.4}, AM2_rho={rho2:.4}, AM3_rho={rho3:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89bf613",
   "metadata": {},
   "outputs": [],
   "source": [
    "AM1m = AM1['Q_S1'].min()\n",
    "AM2m = AM2['Q_S1'].min()\n",
    "AM3m = AM3['Q_S1'].min()\n",
    "print(f'AM1_S1min={AM1m:.2f}, AM2_S1min={AM2m:.2f}, AM3_S1min={AM3m:.2f}')\n",
    "AM1m = AM1['Q_S1'].max()\n",
    "AM2m = AM2['Q_S1'].max()\n",
    "AM3m = AM3['Q_S1'].max()\n",
    "print(f'AM1_S1max={AM1m:.2f}, AM2_S1max={AM2m:.2f}, AM3_S1max={AM3m:.2f}')\n",
    "AM1m = AM1['Q_S2'].min()\n",
    "AM2m = AM2['Q_S2'].min()\n",
    "AM3m = AM3['Q_S2'].min()\n",
    "print(f'AM1_S2min={AM1m:.2f}, AM2_S2min={AM2m:.2f}, AM3_S2min={AM3m:.2f}')\n",
    "AM1m = AM1['Q_S2'].max()\n",
    "AM2m = AM2['Q_S2'].max()\n",
    "AM3m = AM3['Q_S2'].max()\n",
    "print(f'AM1_S2max={AM1m:.2f}, AM2_S2max={AM2m:.2f}, AM3_S2max={AM3m:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e30bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AM1[(AM1.month == 1)&((AM1.day == 1)|(AM1.day == 2)|(AM1.day == 3)|(AM1.day == 4)|(AM1.day == 5)|(AM1.day == 6)|(AM1.day == 7))]\n",
    "AM1[(AM1.month == 12)&((AM1.day == 31)|(AM1.day == 30)|(AM1.day == 29)|(AM1.day == 28)|(AM1.day == 27)|(AM1.day == 26)|(AM1.day == 25))]\n",
    "AM2[(AM2.month == 1)&((AM2.day == 1)|(AM2.day == 2)|(AM2.day == 3)|(AM2.day == 4)|(AM2.day == 5)|(AM2.day == 6)|(AM2.day == 7))]\n",
    "AM2[(AM2.month == 12)&((AM2.day == 31)|(AM2.day == 30)|(AM2.day == 29)|(AM2.day == 28)|(AM2.day == 27)|(AM2.day == 26)|(AM2.day == 25))]\n",
    "# AM2[AM2.month == 1]\n",
    "AM3[(AM3.month == 1)&((AM3.day == 1)|(AM3.day == 2)|(AM3.day == 3)|(AM3.day == 4)|(AM3.day == 5)|(AM3.day == 6)|(AM3.day == 7))]\n",
    "AM3[(AM3.month == 12)&((AM3.day == 31)|(AM3.day == 30)|(AM3.day == 29)|(AM3.day == 28)|(AM3.day == 27)|(AM3.day == 26)|(AM3.day == 25))]\n",
    "# AM3[AM3.month == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 13):\n",
    "#     print(f'{i} - AM1={len(AM1[AM1.month == i])} - AM2={len(AM2[AM2.month == i])} - AM3={len(AM3[AM3.month == i])}')\n",
    "    print(f'{i} - AM1={len(AM1[AM1.month == i])/39960*100:.2f} - AM2={len(AM2[AM2.month == i])/39960*100:.2f} - AM3={len(AM3[AM3.month == i])/39960*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feff8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AM1_hist = []\n",
    "AM2_hist = []\n",
    "AM3_hist = []\n",
    "\n",
    "for i in range(1, 13):\n",
    "    AM1_hist.append(len(AM1_C68[AM1_C68.month == i])) \n",
    "    AM2_hist.append(len(AM2_C68[AM2_C68.month == i])) \n",
    "    AM3_hist.append(len(AM3_C68[AM3_C68.month == i])) \n",
    "#     globals()[f'AM1_m{i}'] = \n",
    "#     globals()[f'AM2_m{i}'] = \n",
    "#     globals()[f'AM3_m{i}'] = \n",
    "\n",
    "#     print(f'{i} - AM1={} - AM2={len(AM2_C68[AM2_C68.month == i])} - AM3={len(AM3_C68[AM3_C68.month == i])}')\n",
    "    \n",
    "    \n",
    "    print(f'{i} - AM1={len(AM1_C68[AM1_C68.month == i])} - AM2={len(AM2_C68[AM2_C68.month == i])} - AM3={len(AM3_C68[AM3_C68.month == i])}')\n",
    "#     print(f'{i} - AM1={len(AM1_C68[AM1_C68.month == i])/49960*100:.2f} - AM2={len(AM2_C68[AM2_C68.month == i])/49960*100:.2f} - AM3={len(AM3_C68[AM3_C68.month == i])/49960*100:.2f}')\n",
    "\n",
    "AM1_hist, AM2_hist, AM3_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AM1m = AM1['Q_S1'].argmin()\n",
    "AM2m = AM2['Q_S1'].argmin()\n",
    "AM3m = AM3['Q_S1'].argmin()\n",
    "print(f'AM1_S1min={AM1m:.0f}, AM2_S1min={AM2m:.0f}, AM3_S1min={AM3m:.0f}')\n",
    "AM1m = AM1['Q_S1'].argmax()\n",
    "AM2m = AM2['Q_S1'].argmax()\n",
    "AM3m = AM3['Q_S1'].argmax()\n",
    "print(f'AM1_S1max={AM1m:.0f}, AM2_S1max={AM2m:.0f}, AM3_S1max={AM3m:.0f}')\n",
    "AM1m = AM1['Q_S2'].argmin()\n",
    "AM2m = AM2['Q_S2'].argmin()\n",
    "AM3m = AM3['Q_S2'].argmin()\n",
    "print(f'AM1_S2min={AM1m:.0f}, AM2_S2min={AM2m:.0f}, AM3_S2min={AM3m:.0f}')\n",
    "AM1m = AM1['Q_S2'].argmax()\n",
    "AM2m = AM2['Q_S2'].argmax()\n",
    "AM3m = AM3['Q_S2'].argmax()\n",
    "print(f'AM1_S2max={AM1m:.0f}, AM2_S2max={AM2m:.0f}, AM3_S2max={AM3m:.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d83a7",
   "metadata": {},
   "source": [
    "### Time series of the peaks (min&max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5, 25):\n",
    "    globals()[f'C68_{j}'] = pd.read_csv(r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\C68_TS\\C68_TS%d.csv\" %j, delimiter=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41340953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAM(self, b1, b2):\n",
    "        \"\"\"\n",
    "        Creates two graphs: \n",
    "            Annual maximas and concurrent flows of the TWO sets\n",
    "            Discharge of TWO points with their annual maxima and concurrent flow\n",
    "        b1, b2: Locations ('Q_#Point1', 'Q_#Point2')\n",
    "        Returns: plot\n",
    "        \"\"\"\n",
    "        self.b1 = b1\n",
    "        self.b2 = b2\n",
    "        s1, s2, am1, am2 = self.AnnualMax(self.b1, self.b2)\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(am1['Year'], am1[self.b1], 'b-o', label=f'{self.b1} Maximun')\n",
    "        plt.plot(am2['Year'], am2[self.b1], 'b--o', label=f'{self.b1}  Concurrent')\n",
    "        plt.plot(am2['Year'], am2[self.b2], 'g-o', label=f'{self.b2} Maximun')\n",
    "        plt.plot(am1['Year'], am1[self.b2], 'g--o', label=f'{self.b2} Concurrent')\n",
    "        plt.title('Annual Maxima')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Discharge (m3/sec)') \n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        self.plotQ(self.b1, self.b2)   \n",
    "        plt.plot(am1['time'], am1[self.b1], color='midnightblue', marker='o', ls='', label=f'{b1} Maximun')\n",
    "        plt.plot(am2['time'], am2[self.b1], color='midnightblue', marker='x', ls='', label=f'{b1}  Concurrent')\n",
    "        plt.plot(am2['time'], am2[self.b2], color='darkolivegreen', marker='o', ls='', label=f'{b2} Maximun')\n",
    "        plt.plot(am1['time'], am1[self.b2], color='darkolivegreen', marker='x', ls='', label=f'{b2} Concurrent')\n",
    "        plt.title('Annual Maxima')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Discharge (m3/sec)') \n",
    "        plt.legend()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = 46560\n",
    "arg = 34559\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(C68_22.Q_S1[C68_22.year == Year], 'b', label='Q_S1')\n",
    "plt.plot(C68_22.Q_S2[C68_22.year == Year], 'g', label='Q_S2')\n",
    "#the maxima\n",
    "plt.plot(AM1.loc[(arg, 'Unnamed: 0')], AM1.loc[(arg, 'Q_S1')], color='midnightblue', marker='o', ls='', label=f'Q_S1 Maximun')\n",
    "plt.plot(AM1.loc[(arg, 'Unnamed: 0')], AM1.loc[(arg, 'Q_S2')], color='darkolivegreen', marker='x', ls='', label=f'Q_S2 Concurrent')\n",
    "plt.plot(AM2.loc[(arg, 'Unnamed: 0')], AM2.loc[(arg, 'Q_S1')], color='midnightblue', marker='x', ls='', label=f'Q_S1 Concurrent')\n",
    "plt.plot(AM2.loc[(arg, 'Unnamed: 0')], AM2.loc[(arg, 'Q_S2')], color='darkolivegreen', marker='o', ls='', label=f'Q_S2 Maximun')\n",
    "plt.axhline(y = np.mean(C68_22.Q_S1), color = 'r', linestyle = '--', label=f'S1_mean')\n",
    "plt.title('S1_max AM1') #Runoff\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Discharge (m3/sec)') # Q m3/s\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d96236",
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = 27654\n",
    "arg = 15653\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(C68_12.Q_S1[C68_12.year == Year], 'b', label='Q_S1')\n",
    "plt.plot(C68_12.Q_S2[C68_12.year == Year], 'g', label='Q_S2')\n",
    "# plt.plot(C68_24.Q_S1[37619:38349], 'b', label='Q_S1') #37900:38000\n",
    "# plt.plot(C68_24.Q_S2[37619:38349], 'g', label='Q_S2')\n",
    "# 37985\n",
    "#the maxima\n",
    "plt.plot(AM1.loc[(arg, 'Unnamed: 0')], AM1.loc[(arg, 'Q_S1')], color='midnightblue', marker='o', ls='', label=f'Q_S1 Maximun')\n",
    "plt.plot(AM1.loc[(arg, 'Unnamed: 0')], AM1.loc[(arg, 'Q_S2')], color='darkolivegreen', marker='x', ls='', label=f'Q_S2 Concurrent')\n",
    "plt.plot(AM2.loc[(arg, 'Unnamed: 0')], AM2.loc[(arg, 'Q_S1')], color='midnightblue', marker='x', ls='', label=f'Q_S1 Concurrent')\n",
    "plt.plot(AM2.loc[(arg, 'Unnamed: 0')], AM2.loc[(arg, 'Q_S2')], color='darkolivegreen', marker='o', ls='', label=f'Q_S2 Maximun')\n",
    "plt.axhline(y = np.mean(C68_12.Q_S1), color = 'r', linestyle = '--', label=f'S1_mean')\n",
    "plt.title('S1_min AM2') #Runoff\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Discharge (m3/sec)') # Q m3/s\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ef91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C68_24.loc[C68_24.year == 50104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = 18748\n",
    "arg = 6747\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(C68_8.Q_S1[C68_8.year == Year], 'b', label='Q_S1')\n",
    "plt.plot(C68_8.Q_S2[C68_8.year == Year], 'g', label='Q_S2')\n",
    "#the maxima\n",
    "plt.plot(AM1.loc[(arg, 'Unnamed: 0')], AM1.loc[(arg, 'Q_S1')], color='midnightblue', marker='o', ls='', label=f'Q_S1 Maximun')\n",
    "plt.plot(AM1.loc[(arg, 'Unnamed: 0')], AM1.loc[(arg, 'Q_S2')], color='darkolivegreen', marker='x', ls='', label=f'Q_S2 Concurrent')\n",
    "plt.plot(AM2.loc[(arg, 'Unnamed: 0')], AM2.loc[(arg, 'Q_S1')], color='midnightblue', marker='x', ls='', label=f'Q_S1 Concurrent')\n",
    "plt.plot(AM2.loc[(arg, 'Unnamed: 0')], AM2.loc[(arg, 'Q_S2')], color='darkolivegreen', marker='o', ls='', label=f'Q_S2 Maximun')\n",
    "plt.axhline(y = np.mean(C68_8.Q_S1), color = 'r', linestyle = '--', label=f'S1_mean')\n",
    "plt.title('S1_min (2) AM1') #Runoff\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Discharge (m3/sec)') # Q m3/s\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa27ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = 51034\n",
    "arg = 39033\n",
    "plt.figure(figsize=(20, 5))\n",
    "# plt.plot(C68_24.Q_S1[C68_24.year == 51033], 'b', label='Q_S1')\n",
    "# plt.plot(C68_24.Q_S2[C68_24.year == 51033], 'g', label='Q_S2')\n",
    "plt.plot(C68_24.Q_S1[377200:377500], 'b', label='Q_S1')\n",
    "plt.plot(C68_24.Q_S2[377200:377500], 'g', label='Q_S2')\n",
    "#the maxima\n",
    "plt.plot(AM1.loc[(arg, 'Unnamed: 0')], AM1.loc[(arg, 'Q_S1')], color='midnightblue', marker='o', ls='', label=f'Q_S1 Maximun')\n",
    "plt.plot(AM1.loc[(arg, 'Unnamed: 0')], AM1.loc[(arg, 'Q_S2')], color='darkolivegreen', marker='x', ls='', label=f'Q_S2 Concurrent')\n",
    "plt.plot(AM2.loc[(arg, 'Unnamed: 0')], AM2.loc[(arg, 'Q_S1')], color='midnightblue', marker='x', ls='', label=f'Q_S1 Concurrent')\n",
    "plt.plot(AM2.loc[(arg, 'Unnamed: 0')], AM2.loc[(arg, 'Q_S2')], color='darkolivegreen', marker='o', ls='', label=f'Q_S2 Maximun')\n",
    "plt.axhline(y = np.mean(C68_24.Q_S2), color = 'r', linestyle = '--', label=f'S2_mean')\n",
    "plt.title('S2_max AMx') #Runoff\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Discharge (m3/sec)') # Q m3/s\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C68_24.Q_S1[C68_24.year == 51034]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5866314",
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = 37174\n",
    "arg = 25173\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(C68_17.Q_S1[C68_17.year == Year], 'b', label='Q_S1')\n",
    "plt.plot(C68_17.Q_S2[C68_17.year == Year], 'g', label='Q_S2')\n",
    "#the maxima\n",
    "plt.plot(AM1.loc[(arg, 'Unnamed: 0')], AM1.loc[(arg, 'Q_S1')], color='midnightblue', marker='o', ls='', label=f'Q_S1 Maximun')\n",
    "plt.plot(AM1.loc[(arg, 'Unnamed: 0')], AM1.loc[(arg, 'Q_S2')], color='darkolivegreen', marker='x', ls='', label=f'Q_S2 Concurrent')\n",
    "plt.plot(AM2.loc[(arg, 'Unnamed: 0')], AM2.loc[(arg, 'Q_S1')], color='midnightblue', marker='x', ls='', label=f'Q_S1 Concurrent')\n",
    "plt.plot(AM2.loc[(arg, 'Unnamed: 0')], AM2.loc[(arg, 'Q_S2')], color='darkolivegreen', marker='o', ls='', label=f'Q_S2 Maximun')\n",
    "plt.axhline(y = np.mean(C68_17.Q_S2), color = 'r', linestyle = '--', label=f'S2_mean')\n",
    "plt.title('S2_min AM1') #Runoff\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Discharge (m3/sec)') # Q m3/s\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dar-cloud')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "dba0fec6c0a5dc3650c48ce5794cc777babb314a0f31f50d55fe76ea6fe6645b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

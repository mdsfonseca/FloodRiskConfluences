{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, spearmanr, kendalltau\n",
    "from scipy.interpolate import griddata \n",
    "from scipy import interpolate\n",
    "import sys\n",
    "\n",
    "import lmom as lmom\n",
    "from datetime import datetime\n",
    "# import openturns as ot\n",
    "# import openturns.viewer as viewer\n",
    "# ot.Log.Show(ot.Log.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 68\n",
    "#Without A&V\n",
    "# op = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HIDnew\\05_HYDzoom\" + r\"\\C%d_\" %c + r\"disc1d_\"\n",
    "#With A&V\n",
    "op = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\RQ2\" + r\"\\C%d_\" %c + r\"disc1d_\"\n",
    "\n",
    "AM1 = pd.read_pickle(op + \"AM1.pkl\")\n",
    "AM2 = pd.read_pickle(op + \"AM2.pkl\")\n",
    "AM3 = pd.read_pickle(op + \"AM3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSpath = r'\\TS_S%d' %rp1 + r'_S%d.csv' %rp2 #  according to Q1_Q2\n",
    "fn = r'P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\RQ3\\Response_functions' \n",
    "\n",
    "sv = r'\\Res_Area.csv'\n",
    "\n",
    "Res_Area = pd.read_csv(fn + sv, delimiter=';')\n",
    "sv = r'\\Res_Volume.csv'\n",
    "Res_Volume = pd.read_csv(fn + sv, delimiter=';')\n",
    "sv = r'\\Res_mDepth.csv'\n",
    "Res_mDepth = pd.read_csv(fn + sv, delimiter=';')\n",
    "\n",
    "\n",
    "Area = Res_Area.iloc[:,1:].values\n",
    "Volume = Res_Volume.iloc[:,1:].values\n",
    "mDepth = Res_mDepth.iloc[:,1:].values\n",
    "# Area\n",
    "\n",
    "\n",
    "S1 = [ 723.95,  3403.62,  6083.29,  8762.96, 11442.62]# np.array([  723.95,  3403.62,  6083.29,  8762.96, 11442.62]) #Colum\n",
    "S2 = [ 27.14, 1119.63, 2212.12, 3304.61, 4397.12]# np.array([  27.14, 1119.63, 2212.12, 3304.61, 4397.12]) #INDEX\n",
    "S1_n = ['S0', 'S1', 'S2', 'S3', 'S4']   #Colum\n",
    "S2_n = ['S0', 'S1', 'S2', 'S3', 'S4']   #INDEX\n",
    "\n",
    "\n",
    "#Interpolation grids\n",
    "x = S1\n",
    "y = S2\n",
    "z = Area\n",
    "fArea = interpolate.interp2d(x, y, z, kind='linear')\n",
    "\n",
    "z = Volume\n",
    "fVolume = interpolate.interp2d(x, y, z, kind='linear')\n",
    "\n",
    "z = mDepth\n",
    "fmDepth = interpolate.interp2d(x, y, z, kind='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(S1, S2)\n",
    "z = Res_Area.iloc[:,1:].values / 1000000\n",
    "cmap = 'YlOrRd'\n",
    "unit = 'm3/s'\n",
    "\n",
    "plt.figure(figsize=(6, 5)) \n",
    "plt.contourf(x, y, z, cmap=cmap)\n",
    "# plt.colorbar()\n",
    "cbar = plt.colorbar(label=\"Area of inundation (km2)\", orientation=\"vertical\") #, fontsize = 16)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "# cbar.ax.set_label(size='large')\n",
    "plt.xticks(fontsize = 12, rotation = 90)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title(f'Response Function\\nArea of inundation', fontsize = 20) \n",
    "plt.xlabel(f'S1 - Rhine River ({unit})', fontsize=16)\n",
    "plt.ylabel(f'S2 - Main River ({unit})', fontsize=16)\n",
    "# plt.grid()    \n",
    "# plt.show()\n",
    "\n",
    "\n",
    "x, y = np.meshgrid(S1, S2)\n",
    "z = Res_Volume.iloc[:,1:].values / 1000000000\n",
    "\n",
    "cmap = 'YlOrRd'\n",
    "unit = 'm3/s'\n",
    "\n",
    "plt.figure(figsize=(6, 5)) \n",
    "plt.contourf(x, y, z, cmap=cmap)\n",
    "# plt.colorbar()\n",
    "cbar = plt.colorbar(label=\"Volume of inundation (km3)\", orientation=\"vertical\") #, fontsize = 16)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "# cbar.ax.set_label(size='large')\n",
    "plt.xticks(fontsize = 12, rotation = 90)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title(f'Response Function\\nVolume of inundation', fontsize = 20) \n",
    "plt.xlabel(f'S1 - Rhine River ({unit})', fontsize=16)\n",
    "plt.ylabel(f'S2 - Main River ({unit})', fontsize=16)\n",
    "# plt.grid()    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark\n",
    "Return Periods\n",
    "T=2, 5, 10, 20, 50, 100, 200, 500, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    \"\"\" Compute Empirical CDF \"\"\"\n",
    "    x = np.sort(data)\n",
    "    n = x.size\n",
    "    rank = np.arange(1, n+1)\n",
    "    y = rank / (n+1)\n",
    "    return x, y\n",
    "\n",
    "def empinv(yp, xed, yed):\n",
    "    xp = []\n",
    "    for i in range(len(yed)):\n",
    "        if yp < yed[0]:\n",
    "            xp=xed[0]\n",
    "            break\n",
    "        elif yp > yed[len(yed)-1]:\n",
    "            xp=(xed[len(yed)-1])\n",
    "            break\n",
    "        elif yp == yed[i-1]:\n",
    "            xp=(xed[i-1])\n",
    "        elif yed[i-1] < yp < yed[i]:\n",
    "            y1 = yed[i-1]\n",
    "            y2 = yed[i]\n",
    "            x1 = xed[i-1]\n",
    "            x2 = xed[i]\n",
    "            xcal = x1 + ((x2-x1)/(y2-y1)) * (yp-y1)\n",
    "            xp=(xcal)\n",
    "        #else:\n",
    "         #   xp.append(xed[len(yed)-1])\n",
    "    return xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S1_n = ['S0', 'S1', 'S2', 'S3', 'S4']   #Colum\n",
    "# S2_n = ['S0', 'S1', 'S2', 'S3', 'S4']   #INDEX\n",
    "# Res_Area = pd.DataFrame(index=[S2_n] ,columns=[S1_n])\n",
    "T = [2, 5, 10, 20, 50, 100, 200, 500, 1000, 5000]\n",
    "Pexc = [1 - 1 / t for t in T]\n",
    "CV=0.05\n",
    "N = [((1/CV)**2)/(1-p) for p in Pexc]\n",
    "col = ['T', 'Pexc', 'N', 'A_Set1', 'A_Set2', 'A_Set3', 'V_Set1', 'V_Set2', 'V_Set3']\n",
    "Tvalues = pd.DataFrame(columns=[col])\n",
    "Tvalues['T'] = np.float64(T)\n",
    "Tvalues['Pexc'] = np.float64(Pexc)\n",
    "Tvalues['N'] = np.float64(N)\n",
    "\n",
    "x, y = ecdf(AM1['Area'])\n",
    "A_Set1 = [empinv(p, x, y)/1000000 for p in Pexc]\n",
    "Tvalues['A_Set1'] = np.float64(A_Set1)\n",
    "\n",
    "x, y = ecdf(AM2['Area'])\n",
    "A_Set2 = [empinv(p, x, y)/1000000 for p in Pexc]\n",
    "Tvalues['A_Set2'] = A_Set2\n",
    "\n",
    "x, y = ecdf(AM3['Area'])\n",
    "A_Set3 = [empinv(p, x, y)/1000000 for p in Pexc]\n",
    "Tvalues['A_Set3'] = A_Set3\n",
    "\n",
    "x, y = ecdf(AM1['Volume'])\n",
    "V_Set1 = [empinv(p, x, y)/1000000000 for p in Pexc]\n",
    "Tvalues['V_Set1'] = V_Set1\n",
    "\n",
    "x, y = ecdf(AM2['Volume'])\n",
    "V_Set2 = [empinv(p, x, y)/1000000000 for p in Pexc]\n",
    "Tvalues['V_Set2'] = V_Set2\n",
    "\n",
    "x, y = ecdf(AM3['Volume'])\n",
    "V_Set3 = [empinv(p, x, y)/1000000000 for p in Pexc]\n",
    "Tvalues['V_Set3'] = V_Set3\n",
    "\n",
    "Tvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\RQ2\\MCruns\\Tvalues.pkl\"\n",
    "Tvalues.to_pickle(sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(S1, S2)\n",
    "z = Res_Area.iloc[:,1:].values / 1000000\n",
    "cmap = 'YlOrRd'\n",
    "unit = 'm3/s'\n",
    "\n",
    "\n",
    "A_levels = np.float64(A_Set1)\n",
    "\n",
    "plt.figure(figsize=(6, 5)) \n",
    "CS = plt.contour(x, y, z, levels=A_levels, cmap=cmap)\n",
    "\n",
    "fmt = {}\n",
    "for l, t in zip(CS.levels, T):\n",
    "    fmt[l] = f'T={t} years'\n",
    "\n",
    "plt.clabel(CS, inline=True, fontsize=10, colors='k', fmt=fmt)\n",
    "plt.xticks(fontsize = 12, rotation = 90)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title(f'Return Periods\\nArea of inundation | Set1', fontsize = 20) \n",
    "plt.xlabel(f'S1 - Rhine River ({unit})', fontsize=16)\n",
    "plt.ylabel(f'S2 - Main River ({unit})', fontsize=16)\n",
    "\n",
    "A_levels = np.float64(A_Set2)\n",
    "\n",
    "plt.figure(figsize=(6, 5)) \n",
    "CS = plt.contour(x, y, z, levels=A_levels, cmap=cmap)\n",
    "\n",
    "fmt = {}\n",
    "for l, t in zip(CS.levels, T):\n",
    "    fmt[l] = f'T={t} years'\n",
    "\n",
    "plt.clabel(CS, inline=True, fontsize=10, colors='k', fmt=fmt)\n",
    "plt.xticks(fontsize = 12, rotation = 90)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title(f'Return Periods\\nArea of inundation | Set2', fontsize = 20) \n",
    "plt.xlabel(f'S1 - Rhine River ({unit})', fontsize=16)\n",
    "plt.ylabel(f'S2 - Main River ({unit})', fontsize=16)\n",
    "\n",
    "A_levels = np.float64(A_Set3)\n",
    "\n",
    "plt.figure(figsize=(6, 5)) \n",
    "CS = plt.contour(x, y, z, levels=A_levels, cmap=cmap)\n",
    "\n",
    "fmt = {}\n",
    "for l, t in zip(CS.levels, T):\n",
    "    fmt[l] = f'T={t} years'\n",
    "\n",
    "plt.clabel(CS, inline=True, fontsize=10, colors='k', fmt=fmt)\n",
    "plt.xticks(fontsize = 12, rotation = 90)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title(f'Return Periods\\nArea of inundation | Set3', fontsize = 20) \n",
    "plt.xlabel(f'S1 - Rhine River ({unit})', fontsize=16)\n",
    "plt.ylabel(f'S2 - Main River ({unit})', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x, y = np.meshgrid(S1, S2)\n",
    "z = Res_Volume.iloc[:,1:].values / 1000000000\n",
    "cmap = 'YlOrRd'\n",
    "unit = 'm3/s'\n",
    "\n",
    "\n",
    "V_levels = np.float64(V_Set1)\n",
    "\n",
    "plt.figure(figsize=(6, 5)) \n",
    "CS = plt.contour(x, y, z, levels=V_levels, cmap=cmap)\n",
    "\n",
    "fmt = {}\n",
    "for l, t in zip(CS.levels, T):\n",
    "    fmt[l] = f'T={t} years'\n",
    "\n",
    "plt.clabel(CS, inline=True, fontsize=10, colors='k', fmt=fmt)\n",
    "plt.xticks(fontsize = 12, rotation = 90)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title(f'Return Periods\\nVolume of inundation | Set1', fontsize = 20) \n",
    "plt.xlabel(f'S1 - Rhine River ({unit})', fontsize=16)\n",
    "plt.ylabel(f'S2 - Main River ({unit})', fontsize=16)\n",
    "\n",
    "V_levels = np.float64(V_Set2)\n",
    "\n",
    "plt.figure(figsize=(6, 5)) \n",
    "CS = plt.contour(x, y, z, levels=V_levels, cmap=cmap)\n",
    "\n",
    "fmt = {}\n",
    "for l, t in zip(CS.levels, T):\n",
    "    fmt[l] = f'T={t} years'\n",
    "\n",
    "plt.clabel(CS, inline=True, fontsize=10, colors='k', fmt=fmt)\n",
    "plt.xticks(fontsize = 12, rotation = 90)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title(f'Return Periods\\nVolume of inundation | Set2', fontsize = 20) \n",
    "plt.xlabel(f'S1 - Rhine River ({unit})', fontsize=16)\n",
    "plt.ylabel(f'S2 - Main River ({unit})', fontsize=16)\n",
    "\n",
    "V_levels = np.float64(V_Set3)\n",
    "\n",
    "plt.figure(figsize=(6, 5)) \n",
    "CS = plt.contour(x, y, z, levels=V_levels, cmap=cmap)\n",
    "\n",
    "fmt = {}\n",
    "for l, t in zip(CS.levels, T):\n",
    "    fmt[l] = f'T={t} years'\n",
    "\n",
    "plt.clabel(CS, inline=True, fontsize=10, colors='k', fmt=fmt)\n",
    "plt.xticks(fontsize = 12, rotation = 90)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title(f'Return Periods\\nVolume of inundation | Set3', fontsize = 20) \n",
    "plt.xlabel(f'S1 - Rhine River ({unit})', fontsize=16)\n",
    "plt.ylabel(f'S2 - Main River ({unit})', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation of the design flood event: Copulas + Monte Carlo Sampling (+Bootstrapping experiment)\n",
    "\n",
    "T-area and T-volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full data..\n",
    "\n",
    "Marginals: Empiricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GauR(AMset, n):\n",
    "    rho, Sp = spearmanr(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    tau, Kp = kendalltau(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    fp1, xp1 = ecdf(AMset['Q_S1'])\n",
    "    fp2, xp2 = ecdf(AMset['Q_S2'])\n",
    "    \n",
    "    Area = np.zeros(n)\n",
    "    Volume = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        p1 = np.random.rand(1)\n",
    "        p2 = np.random.rand(1)\n",
    "        u1 = norm.ppf(p1)\n",
    "        u2 = norm.ppf(p2)\n",
    "        u1_ = u1\n",
    "        u2_ = rho * u1 + np.sqrt(1 - rho**2) * u2\n",
    "        p1_ = norm.cdf(u1_)\n",
    "        p2_ = norm.cdf(u2_)    \n",
    "        D1 = np.interp(p1_, xp1, fp1)\n",
    "        D2 = np.interp(p2_, xp2, fp2) \n",
    "        Area[i] = fArea(D1, D2)[0]\n",
    "        Volume[i] = fVolume(D1, D2)[0]\n",
    "        \n",
    "    return Area, Volume\n",
    "\n",
    "\n",
    "def GumR(AMset, n):\n",
    "    rho, Sp = spearmanr(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    tau, Kp = kendalltau(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    fp1, xp1 = ecdf(AMset['Q_S1'])\n",
    "    fp2, xp2 = ecdf(AMset['Q_S2'])\n",
    "    \n",
    "    Area = np.zeros(n)\n",
    "    Volume = np.zeros(n)\n",
    "        \n",
    "    alpha = 1 / (1-tau)\n",
    "    \n",
    "    #lookup table\n",
    "    x1 = np.arange(0.0000000001, 0.000000001, 0.0000000001)\n",
    "    x2 = x1 * 10\n",
    "    x3 = x2 * 10\n",
    "    x4 = x3 * 10\n",
    "    x5 = x4 * 10\n",
    "    x6 = x5 * 10\n",
    "    x7 = x6 * 10\n",
    "    x8 = x7 * 10\n",
    "    x9 = np.arange(x8[-1]+0.001, 0.999, 0.001)\n",
    "    x10 = np.arange(0.999, 0.9999, 0.0001)\n",
    "    x11 = np.arange(0.9999, 0.99999, 0.00001)\n",
    "    x12 = np.arange(0.99999, 1, 0.000001)\n",
    "    x = np.concatenate((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12))\n",
    "    y = alpha * ((-np.log(x))** alpha)/(x*np.log(x))\n",
    "    ltable = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "    for i in range(n):\n",
    "        u = np.random.rand(1)\n",
    "        t = np.random.rand(1)\n",
    "        phi_u = alpha * ((-np.log(u))**alpha)/(u*np.log(u))\n",
    "        phi_w = phi_u / t\n",
    "        \n",
    "        w = np.interp(phi_w, ltable['y'], ltable['x'])\n",
    "        s = ((-np.log(w)) ** alpha ) - ((-np.log(u)) ** alpha )\n",
    "        v = np.exp(-(s**(1/alpha)))\n",
    "\n",
    "        D1 = np.interp(u, xp1, fp1)\n",
    "        D2 = np.interp(v, xp2, fp2)\n",
    "\n",
    "        Area[i] = fArea(D1, D2)[0]\n",
    "        Volume[i] = fVolume(D1, D2)[0]\n",
    "\n",
    "    return Area, Volume\n",
    "    \n",
    "\n",
    "def ClaR(AMset, n):\n",
    "    rho, Sp = spearmanr(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    tau, Kp = kendalltau(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    fp1, xp1 = ecdf(AMset['Q_S1'])\n",
    "    fp2, xp2 = ecdf(AMset['Q_S2'])\n",
    "    Area = np.zeros(n)\n",
    "    Volume = np.zeros(n)\n",
    "    alpha = (2 * tau) / (1-tau)\n",
    "    \n",
    "    #lookup table\n",
    "    x1 = np.arange(0.0000000001, 0.000000001, 0.0000000001)\n",
    "    x2 = x1 * 10\n",
    "    x3 = x2 * 10\n",
    "    x4 = x3 * 10\n",
    "    x5 = x4 * 10\n",
    "    x6 = x5 * 10\n",
    "    x7 = x6 * 10\n",
    "    x8 = x7 * 10\n",
    "    x9 = np.arange(x8[-1]+0.001, 0.999, 0.001)\n",
    "    x10 = np.arange(0.999, 0.9999, 0.0001)\n",
    "    x11 = np.arange(0.9999, 0.99999, 0.00001)\n",
    "    x12 = np.arange(0.99999, 1, 0.000001)\n",
    "    x = np.concatenate((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12))\n",
    "    y = - ( x ** ( -1 - alpha))\n",
    "    ltable = pd.DataFrame({'x':x, 'y':y})\n",
    "    \n",
    "    for i in range(n):\n",
    "        u = np.random.rand(1)\n",
    "        t = np.random.rand(1)\n",
    "        phi_u =  -(u ** (-1 - alpha))\n",
    "        phi_w = phi_u / t\n",
    "        \n",
    "        w = np.interp(phi_w, ltable['y'], ltable['x'])\n",
    "        s = ((w ** (-alpha))-1)/alpha-((u ** (-alpha))-1)/alpha\n",
    "        v = (alpha * s +1) ** (-1/alpha)\n",
    "\n",
    "        D1 = np.interp(u, xp1, fp1)\n",
    "        D2 = np.interp(v, xp2, fp2)\n",
    "\n",
    "        Area[i] = fArea(D1, D2)[0]\n",
    "        Volume[i] = fVolume(D1, D2)[0]\n",
    "\n",
    "    return Area, Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb = 100 #Bootstrapping experiment\n",
    "\n",
    "T = [2, 5, 10, 20, 50, 100, 200, 500, 1000, 5000]\n",
    "Pexc = [1 - 1 / t for t in T]\n",
    "\n",
    "AMs = ['AM2', 'AM3'] #'AM1', \n",
    "n = 200000   # CV=5% for T=500\n",
    "\n",
    "Nsam = 50000\n",
    "\n",
    "for AM in AMs:\n",
    "    print(f'Starting {AM} at {str(datetime.now().time())}')\n",
    "    if AM == 'AM1':\n",
    "        AMset = AM1 \n",
    "    elif AM == 'AM2':\n",
    "        AMset = AM2\n",
    "    elif AM == 'AM3':\n",
    "        AMset = AM1 \n",
    "    \n",
    "    globals()[f'N{Nsam}_{AM}_Agau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    \n",
    "    for i in range(Nb):\n",
    "        print(f'{i} at {str(datetime.now().time())}')\n",
    "        Area, Volume = GauR(AMset, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gau = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gau = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agau'].loc[i] = A_gau\n",
    "        globals()[f'N{Nsam}_{AM}_Vgau'].loc[i] = V_gau\n",
    "\n",
    "        Area, Volume = GumR(AMset, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gum = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gum = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agum'].loc[i] = A_gum\n",
    "        globals()[f'N{Nsam}_{AM}_Vgum'].loc[i] = V_gum\n",
    "\n",
    "\n",
    "        Area, Volume = ClaR(AMset, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_cla = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_cla = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Acla'].loc[i] = A_cla\n",
    "        globals()[f'N{Nsam}_{AM}_Vcla'].loc[i] = V_cla\n",
    "    \n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\RQ2\\MCruns\\Ts\\N%d\" %Nsam + r\"_\" + AM\n",
    "    desc = r\"_Agau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Agum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Acla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vcla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'].to_pickle(sv+desc)\n",
    "    \n",
    "    print(f'Done {AM} at {str(datetime.now().time())}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples 'N' size..\n",
    "\n",
    "\n",
    "N= 20, 50, 100, 500, 1000\n",
    "Marginals: Metrics fit (alternative 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GauR_n(AM, AMs, Nsam, n):\n",
    "    AMs['ind'] = np.arange(len(AMs))\n",
    "    randomindex1 = np.random.choice(AMs.ind, size=Nsam, replace=False)\n",
    "    AMset = pd.DataFrame()\n",
    "    for i in range(Nsam):\n",
    "        # AMset = AMset.append(AMs.loc[AMs.ind == randomindex1[i]])\n",
    "        AMset = pd.concat([AMset, AMs.loc[AMs.ind == randomindex1[i]]])\n",
    "    \n",
    "    rho, Sp = spearmanr(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    tau, Kp = kendalltau(AMset['Q_S1'], AMset['Q_S2'])\n",
    "\n",
    "    #Marginals\n",
    "    LMU1 = lmom.samlmu(AMset['Q_S1'])\n",
    "    LMU2 = lmom.samlmu(AMset['Q_S2'])\n",
    "\n",
    "    if AM == 'AM1':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgpa(LMU2)  \n",
    "    elif AM == 'AM2':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgev(LMU2)\n",
    "    elif AM == 'AM3':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgpa(LMU2)\n",
    "\n",
    "    Area = np.zeros(n)\n",
    "    Volume = np.zeros(n)\n",
    "    for i in range(n): \n",
    "        p1 = np.random.rand(1)\n",
    "        p2 = np.random.rand(1)\n",
    "        u1 = norm.ppf(p1)\n",
    "        u2 = norm.ppf(p2)\n",
    "        u1_ = u1\n",
    "        u2_ = rho * u1 + np.sqrt(1 - rho**2) * u2\n",
    "        p1_ = norm.cdf(u1_)\n",
    "        p2_ = norm.cdf(u2_)   \n",
    "\n",
    "        if AM == 'AM1':\n",
    "            D1 = lmom.quagev(p1_, fit1)\n",
    "            D2 = lmom.quagpa(p2_, fit2)\n",
    "        elif AM == 'AM2':\n",
    "            D1 = lmom.quagev(p1_, fit1)\n",
    "            D2 = lmom.quagev(p2_, fit2)\n",
    "            \n",
    "        elif AM == 'AM3':\n",
    "            D1 = lmom.quagev(p1_, fit1)\n",
    "            D2 = lmom.quagpa(p2_, fit2)\n",
    "\n",
    "\n",
    "        Area[i] = fArea(D1, D2)[0]\n",
    "        Volume[i] = fVolume(D1, D2)[0]\n",
    "        \n",
    "    return Area, Volume\n",
    "\n",
    "\n",
    "def GumR_n(AM, AMs, Nsam, n):\n",
    "    AMs['ind'] = np.arange(len(AMs))\n",
    "    randomindex1 = np.random.choice(AMs.ind, size=Nsam, replace=False)\n",
    "    AMset = pd.DataFrame()\n",
    "    for i in range(Nsam):\n",
    "        # AMset = AMset.append(AMs.loc[AMs.ind == randomindex1[i]])\n",
    "        AMset = pd.concat([AMset, AMs.loc[AMs.ind == randomindex1[i]]])\n",
    "    \n",
    "    rho, Sp = spearmanr(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    tau, Kp = kendalltau(AMset['Q_S1'], AMset['Q_S2'])\n",
    "\n",
    "    #Marginals\n",
    "    LMU1 = lmom.samlmu(AMset['Q_S1'])\n",
    "    LMU2 = lmom.samlmu(AMset['Q_S2'])\n",
    "\n",
    "    if AM == 'AM1':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgpa(LMU2)  \n",
    "    elif AM == 'AM2':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgev(LMU2)\n",
    "        \n",
    "    elif AM == 'AM3':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgpa(LMU2)\n",
    "\n",
    "    Area = np.zeros(n)\n",
    "    Volume = np.zeros(n)\n",
    "\n",
    "    alpha = 1 / (1-tau)\n",
    "    \n",
    "    #lookup table\n",
    "    x1 = np.arange(0.0000000001, 0.000000001, 0.0000000001)\n",
    "    x2 = x1 * 10\n",
    "    x3 = x2 * 10\n",
    "    x4 = x3 * 10\n",
    "    x5 = x4 * 10\n",
    "    x6 = x5 * 10\n",
    "    x7 = x6 * 10\n",
    "    x8 = x7 * 10\n",
    "    x9 = np.arange(x8[-1]+0.001, 0.999, 0.001)\n",
    "    x10 = np.arange(0.999, 0.9999, 0.0001)\n",
    "    x11 = np.arange(0.9999, 0.99999, 0.00001)\n",
    "    x12 = np.arange(0.99999, 1, 0.000001)\n",
    "    x = np.concatenate((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12))\n",
    "    y = alpha * ((-np.log(x))** alpha)/(x*np.log(x))\n",
    "    ltable = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "    for i in range(n):\n",
    "        u = np.random.rand(1)\n",
    "        t = np.random.rand(1)\n",
    "        phi_u = alpha * ((-np.log(u))**alpha)/(u*np.log(u))\n",
    "        phi_w = phi_u / t\n",
    "        \n",
    "        w = np.interp(phi_w, ltable['y'], ltable['x'])\n",
    "        s = ((-np.log(w)) ** alpha ) - ((-np.log(u)) ** alpha )\n",
    "        v = np.exp(-(s**(1/alpha)))\n",
    "        \n",
    "        if AM == 'AM1':\n",
    "            D1 = lmom.quagev(u, fit1)\n",
    "            D2 = lmom.quagpa(v, fit2)\n",
    "        elif AM == 'AM2':\n",
    "            D1 = lmom.quagev(u, fit1)\n",
    "            D2 = lmom.quagev(v, fit2) \n",
    "        elif AM == 'AM3':\n",
    "            D1 = lmom.quagev(u, fit1)\n",
    "            D2 = lmom.quagpa(v, fit2)\n",
    "\n",
    "        Area[i] = fArea(D1, D2)[0]\n",
    "        Volume[i] = fVolume(D1, D2)[0]\n",
    "\n",
    "    return Area, Volume\n",
    "    \n",
    "\n",
    "def ClaR_n(AM, AMs, Nsam, n):\n",
    "    AMs['ind'] = np.arange(len(AMs))\n",
    "    randomindex1 = np.random.choice(AMs.ind, size=Nsam, replace=False)\n",
    "    AMset = pd.DataFrame()\n",
    "    for i in range(Nsam):\n",
    "        # AMset = AMset.append(AMs.loc[AMs.ind == randomindex1[i]])\n",
    "        AMset = pd.concat([AMset, AMs.loc[AMs.ind == randomindex1[i]]])\n",
    "    \n",
    "    rho, Sp = spearmanr(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    tau, Kp = kendalltau(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    \n",
    "    #Marginals\n",
    "    LMU1 = lmom.samlmu(AMset['Q_S1'])\n",
    "    LMU2 = lmom.samlmu(AMset['Q_S2'])\n",
    "\n",
    "    if AM == 'AM1':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgpa(LMU2)  \n",
    "    elif AM == 'AM2':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgev(LMU2)\n",
    "    elif AM == 'AM3':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgpa(LMU2)\n",
    "        \n",
    "    Area = np.zeros(n)\n",
    "    Volume = np.zeros(n)\n",
    "    \n",
    "    alpha = (2 * tau) / (1-tau)\n",
    "    \n",
    "    #lookup table\n",
    "    x1 = np.arange(0.0000000001, 0.000000001, 0.0000000001)\n",
    "    x2 = x1 * 10\n",
    "    x3 = x2 * 10\n",
    "    x4 = x3 * 10\n",
    "    x5 = x4 * 10\n",
    "    x6 = x5 * 10\n",
    "    x7 = x6 * 10\n",
    "    x8 = x7 * 10\n",
    "    x9 = np.arange(x8[-1]+0.001, 0.999, 0.001)\n",
    "    x10 = np.arange(0.999, 0.9999, 0.0001)\n",
    "    x11 = np.arange(0.9999, 0.99999, 0.00001)\n",
    "    x12 = np.arange(0.99999, 1, 0.000001)\n",
    "    x = np.concatenate((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12))\n",
    "    y = - ( x ** ( -1 - alpha))\n",
    "    ltable = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "    # for i in range(n):\n",
    "    iter = 0\n",
    "    while iter<n:\n",
    "        u = np.random.rand(1)\n",
    "        t = np.random.rand(1)\n",
    "        phi_u =  -(u ** (-1 - alpha))\n",
    "        phi_w = phi_u / t\n",
    "        \n",
    "        w = np.interp(phi_w, ltable['y'], ltable['x'])\n",
    "        s = ((w ** (-alpha))-1)/alpha-((u ** (-alpha))-1)/alpha\n",
    "        v = (alpha * s +1) ** (-1/alpha)\n",
    "\n",
    "        if AM == 'AM1':\n",
    "            D1 = lmom.quagev(u, fit1)\n",
    "            D2 = lmom.quagpa(v, fit2)\n",
    "        elif AM == 'AM2':\n",
    "            D1 = lmom.quagev(u, fit1)\n",
    "            D2 = lmom.quagev(v, fit2)\n",
    "        elif AM == 'AM3':\n",
    "            D1 = lmom.quagev(u, fit1)\n",
    "            D2 = lmom.quagpa(v, fit2)\n",
    "\n",
    "        if D1 != None:\n",
    "            if D2 != None:\n",
    "                Area[iter] = fArea(D1, D2)[0]\n",
    "                Volume[iter] = fVolume(D1, D2)[0]\n",
    "                iter+=1\n",
    "        else:\n",
    "            iter+=0\n",
    "            \n",
    "    return Area, Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N=[20, 50, 100, 500, 1000]\n",
    "Nsam = CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Nb = 100 #Bootstrapping experiment\n",
    "\n",
    "T = [2, 5, 10, 20, 50, 100, 200, 500, 1000, 5000]\n",
    "Pexc = [1 - 1 / t for t in T]\n",
    "\n",
    "AMs = ['AM1'] #'AM1', 'AM2', 'AM3'\n",
    "n = 200000   # CV=5% for T=500 MCiterations\n",
    "\n",
    "Nsam = 20 #[20, 50, 100, 500, 1000] Size of the random sample\n",
    "\n",
    "for AM in AMs:\n",
    "    print(f'Starting {AM} at {str(datetime.now().time())}')\n",
    "    if AM == 'AM1':\n",
    "        AMset = AM1 \n",
    "    elif AM == 'AM2':\n",
    "        AMset = AM2\n",
    "    elif AM == 'AM3':\n",
    "        AMset = AM1 \n",
    "    \n",
    "    globals()[f'N{Nsam}_{AM}_Agau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    \n",
    "    for i in range(Nb):\n",
    "        print(f'{i} - {str(datetime.now().time())}')\n",
    "        Area, Volume = GauR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gau = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gau = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agau'].loc[i] = A_gau\n",
    "        globals()[f'N{Nsam}_{AM}_Vgau'].loc[i] = V_gau\n",
    "\n",
    "        Area, Volume = GumR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gum = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gum = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agum'].loc[i] = A_gum\n",
    "        globals()[f'N{Nsam}_{AM}_Vgum'].loc[i] = V_gum\n",
    "\n",
    "        Area, Volume = ClaR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_cla = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_cla = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Acla'].loc[i] = A_cla\n",
    "        globals()[f'N{Nsam}_{AM}_Vcla'].loc[i] = V_cla\n",
    "    \n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\RQ2\\MCruns\\Ts\\N%d\" %Nsam + r\"_\" + AM\n",
    "    desc = r\"_Agau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Agum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Acla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vcla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'].to_pickle(sv+desc)\n",
    "    \n",
    "    print(f'Done {AM} at {str(datetime.now().time())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Nb = 100 #Bootstrapping experiment\n",
    "\n",
    "T = [2, 5, 10, 20, 50, 100, 200, 500, 1000, 5000]\n",
    "Pexc = [1 - 1 / t for t in T]\n",
    "\n",
    "AMs = ['AM1'] #'AM1', 'AM2', 'AM3'\n",
    "n = 200000   # CV=5% for T=500 MCiterations\n",
    "\n",
    "Nsam = 50 #[20, 50, 100, 500, 1000] Size of the random sample\n",
    "\n",
    "for AM in AMs:\n",
    "    print(f'Starting {AM} at {str(datetime.now())}')\n",
    "    if AM == 'AM1':\n",
    "        AMset = AM1 \n",
    "    elif AM == 'AM2':\n",
    "        AMset = AM2\n",
    "    elif AM == 'AM3':\n",
    "        AMset = AM1 \n",
    "    \n",
    "    globals()[f'N{Nsam}_{AM}_Agau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    \n",
    "    for i in range(Nb):\n",
    "        print(f'{i} - {str(datetime.now().time())}')\n",
    "        Area, Volume = GauR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gau = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gau = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agau'].loc[i] = A_gau\n",
    "        globals()[f'N{Nsam}_{AM}_Vgau'].loc[i] = V_gau\n",
    "\n",
    "        Area, Volume = GumR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gum = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gum = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agum'].loc[i] = A_gum\n",
    "        globals()[f'N{Nsam}_{AM}_Vgum'].loc[i] = V_gum\n",
    "\n",
    "        Area, Volume = ClaR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_cla = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_cla = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Acla'].loc[i] = A_cla\n",
    "        globals()[f'N{Nsam}_{AM}_Vcla'].loc[i] = V_cla\n",
    "    \n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\RQ2\\MCruns\\Ts\\N%d\" %Nsam + r\"_\" + AM\n",
    "    desc = r\"_Agau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Agum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Acla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vcla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'].to_pickle(sv+desc)\n",
    "    \n",
    "    print(f'Done {AM} at {str(datetime.now().time())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb = 100 #Bootstrapping experiment\n",
    "\n",
    "T = [2, 5, 10, 20, 50, 100, 200, 500, 1000, 5000]\n",
    "Pexc = [1 - 1 / t for t in T]\n",
    "\n",
    "AMs = ['AM1'] #'AM1', 'AM2', 'AM3'\n",
    "n = 200000   # CV=5% for T=500 MCiterations\n",
    "\n",
    "Nsam = 100 #[20, 50, 100, 500, 1000] Size of the random sample\n",
    "\n",
    "for AM in AMs:\n",
    "    print(f'Starting {AM} at {str(datetime.now())}')\n",
    "    if AM == 'AM1':\n",
    "        AMset = AM1 \n",
    "    elif AM == 'AM2':\n",
    "        AMset = AM2\n",
    "    elif AM == 'AM3':\n",
    "        AMset = AM1 \n",
    "    \n",
    "    globals()[f'N{Nsam}_{AM}_Agau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    \n",
    "    for i in range(Nb):\n",
    "        print(f'{i} - {str(datetime.now().time())}')\n",
    "        Area, Volume = GauR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gau = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gau = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agau'].loc[i] = A_gau\n",
    "        globals()[f'N{Nsam}_{AM}_Vgau'].loc[i] = V_gau\n",
    "\n",
    "        Area, Volume = GumR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gum = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gum = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agum'].loc[i] = A_gum\n",
    "        globals()[f'N{Nsam}_{AM}_Vgum'].loc[i] = V_gum\n",
    "\n",
    "        Area, Volume = ClaR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_cla = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_cla = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Acla'].loc[i] = A_cla\n",
    "        globals()[f'N{Nsam}_{AM}_Vcla'].loc[i] = V_cla\n",
    "    \n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\RQ2\\MCruns\\Ts\\N%d\" %Nsam + r\"_\" + AM\n",
    "    desc = r\"_Agau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Agum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Acla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vcla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'].to_pickle(sv+desc)\n",
    "    \n",
    "    print(f'Done {AM} at {str(datetime.now().time())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Nb = 100 #Bootstrapping experiment\n",
    "\n",
    "T = [2, 5, 10, 20, 50, 100, 200, 500, 1000, 5000]\n",
    "Pexc = [1 - 1 / t for t in T]\n",
    "\n",
    "AMs = ['AM1'] #'AM1', 'AM2', 'AM3'\n",
    "n = 200000   # CV=5% for T=500 MCiterations\n",
    "\n",
    "Nsam = 500 #[20, 50, 100, 500, 1000] Size of the random sample\n",
    "\n",
    "for AM in AMs:\n",
    "    print(f'Starting {AM} at {str(datetime.now())}')\n",
    "    if AM == 'AM1':\n",
    "        AMset = AM1 \n",
    "    elif AM == 'AM2':\n",
    "        AMset = AM2\n",
    "    elif AM == 'AM3':\n",
    "        AMset = AM1 \n",
    "    \n",
    "    globals()[f'N{Nsam}_{AM}_Agau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    \n",
    "    for i in range(Nb):\n",
    "        print(f'{i} - {str(datetime.now().time())}')\n",
    "        Area, Volume = GauR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gau = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gau = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agau'].loc[i] = A_gau\n",
    "        globals()[f'N{Nsam}_{AM}_Vgau'].loc[i] = V_gau\n",
    "\n",
    "        Area, Volume = GumR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gum = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gum = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agum'].loc[i] = A_gum\n",
    "        globals()[f'N{Nsam}_{AM}_Vgum'].loc[i] = V_gum\n",
    "\n",
    "        Area, Volume = ClaR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_cla = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_cla = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Acla'].loc[i] = A_cla\n",
    "        globals()[f'N{Nsam}_{AM}_Vcla'].loc[i] = V_cla\n",
    "    \n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\RQ2\\MCruns\\Ts\\N%d\" %Nsam + r\"_\" + AM\n",
    "    desc = r\"_Agau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Agum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Acla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vcla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'].to_pickle(sv+desc)\n",
    "    \n",
    "    print(f'Done {AM} at {str(datetime.now().time())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb = 100 #Bootstrapping experiment\n",
    "\n",
    "T = [2, 5, 10, 20, 50, 100, 200, 500, 1000, 5000]\n",
    "Pexc = [1 - 1 / t for t in T]\n",
    "\n",
    "AMs = ['AM1'] #, 'AM1', 'AM3'\n",
    "n = 200000   # CV=5% for T=500 MCiterations\n",
    "\n",
    "Nsam = 1000 #[20, 50, 100, 500, 1000] Size of the random sample\n",
    "\n",
    "for AM in AMs:\n",
    "    print(f'Starting {AM} at {str(datetime.now())}')\n",
    "    if AM == 'AM1':\n",
    "        AMset = AM1 \n",
    "    elif AM == 'AM2':\n",
    "        AMset = AM2\n",
    "    elif AM == 'AM3':\n",
    "        AMset = AM1 \n",
    "    \n",
    "    globals()[f'N{Nsam}_{AM}_Agau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    \n",
    "    for i in range(Nb):\n",
    "        print(f'{i} - {str(datetime.now().time())}')\n",
    "        Area, Volume = GauR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gau = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gau = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agau'].loc[i] = A_gau\n",
    "        globals()[f'N{Nsam}_{AM}_Vgau'].loc[i] = V_gau\n",
    "\n",
    "        Area, Volume = GumR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gum = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gum = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agum'].loc[i] = A_gum\n",
    "        globals()[f'N{Nsam}_{AM}_Vgum'].loc[i] = V_gum\n",
    "\n",
    "\n",
    "        Area, Volume = ClaR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_cla = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_cla = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Acla'].loc[i] = A_cla\n",
    "        globals()[f'N{Nsam}_{AM}_Vcla'].loc[i] = V_cla\n",
    "    \n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\RQ2\\MCruns\\Ts\\N%d\" %Nsam + r\"_\" + AM\n",
    "    desc = r\"_Agau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Agum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Acla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vcla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'].to_pickle(sv+desc)\n",
    "    \n",
    "    print(f'Done {AM} at {str(datetime.now().time())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Nb = 100 #Bootstrapping experiment\n",
    "\n",
    "T = [2, 5, 10, 20, 50, 100, 200, 500, 1000, 5000]\n",
    "Pexc = [1 - 1 / t for t in T]\n",
    "\n",
    "AMs = ['AM1', 'AM2', 'AM3'] #, 'AM2', 'AM3'\n",
    "n = 200000   # CV=5% for T=500 MCiterations\n",
    "\n",
    "Nsam = 5000 #[20, 50, 100, 500, 1000] Size of the random sample\n",
    "\n",
    "for AM in AMs:\n",
    "    print(f'Starting {AM} at {str(datetime.now())}')\n",
    "    if AM == 'AM1':\n",
    "        AMset = AM1 \n",
    "    elif AM == 'AM2':\n",
    "        AMset = AM2\n",
    "    elif AM == 'AM3':\n",
    "        AMset = AM1 \n",
    "    \n",
    "    globals()[f'N{Nsam}_{AM}_Agau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    \n",
    "    for i in range(Nb):\n",
    "        print(f'{i} - {str(datetime.now().time())}')\n",
    "        Area, Volume = GauR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gau = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gau = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agau'].loc[i] = A_gau\n",
    "        globals()[f'N{Nsam}_{AM}_Vgau'].loc[i] = V_gau\n",
    "\n",
    "        Area, Volume = GumR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gum = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gum = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agum'].loc[i] = A_gum\n",
    "        globals()[f'N{Nsam}_{AM}_Vgum'].loc[i] = V_gum\n",
    "\n",
    "\n",
    "        Area, Volume = ClaR_n(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_cla = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_cla = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Acla'].loc[i] = A_cla\n",
    "        globals()[f'N{Nsam}_{AM}_Vcla'].loc[i] = V_cla\n",
    "    \n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\RQ2\\MCruns\\Ts\\N%d\" %Nsam + r\"_\" + AM\n",
    "    desc = r\"_Agau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgau.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Agum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgum.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Acla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vcla.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'].to_pickle(sv+desc)\n",
    "    \n",
    "    print(f'Done {AM} at {str(datetime.now().time())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity analysis for the selection of the marginal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginals accoding to log plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GauR_n2(AM, AMs, Nsam, n):\n",
    "    AMs['ind'] = np.arange(len(AMs))\n",
    "    randomindex1 = np.random.choice(AMs.ind, size=Nsam, replace=False)\n",
    "    AMset = pd.DataFrame()\n",
    "    for i in range(Nsam):\n",
    "        # AMset = AMset.append(AMs.loc[AMs.ind == randomindex1[i]])\n",
    "        AMset = pd.concat([AMset, AMs.loc[AMs.ind == randomindex1[i]]])\n",
    "    \n",
    "    rho, Sp = spearmanr(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    tau, Kp = kendalltau(AMset['Q_S1'], AMset['Q_S2'])\n",
    "\n",
    "    #Marginals\n",
    "    LMU1 = lmom.samlmu(AMset['Q_S1'])\n",
    "    LMU2 = lmom.samlmu(AMset['Q_S2'])\n",
    "\n",
    "    if AM == 'AM1':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgpa(LMU2)  \n",
    "    elif AM == 'AM2':\n",
    "        fit1 = lmom.pelgum(LMU1)\n",
    "        fit2 = lmom.pelgum(LMU2)\n",
    "    elif AM == 'AM3':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgum(LMU2)\n",
    "\n",
    "    Area = np.zeros(n)\n",
    "    Volume = np.zeros(n)\n",
    "    for i in range(n): \n",
    "        p1 = np.random.rand(1)\n",
    "        p2 = np.random.rand(1)\n",
    "        u1 = norm.ppf(p1)\n",
    "        u2 = norm.ppf(p2)\n",
    "        u1_ = u1\n",
    "        u2_ = rho * u1 + np.sqrt(1 - rho**2) * u2\n",
    "        p1_ = norm.cdf(u1_)\n",
    "        p2_ = norm.cdf(u2_)   \n",
    "\n",
    "        if AM == 'AM1':\n",
    "            D1 = lmom.quagev(p1_, fit1)\n",
    "            D2 = lmom.quagpa(p2_, fit2)\n",
    "        elif AM == 'AM2':\n",
    "            D1 = lmom.quagum(p1_, fit1)\n",
    "            D2 = lmom.quagum(p2_, fit2)\n",
    "            \n",
    "        elif AM == 'AM3':\n",
    "            D1 = lmom.quagev(p1_, fit1)\n",
    "            D2 = lmom.quagum(p2_, fit2)\n",
    "\n",
    "\n",
    "        Area[i] = fArea(D1, D2)[0]\n",
    "        Volume[i] = fVolume(D1, D2)[0]\n",
    "        \n",
    "    return Area, Volume\n",
    "\n",
    "\n",
    "def GumR_n2(AM, AMs, Nsam, n):\n",
    "    AMs['ind'] = np.arange(len(AMs))\n",
    "    randomindex1 = np.random.choice(AMs.ind, size=Nsam, replace=False)\n",
    "    AMset = pd.DataFrame()\n",
    "    for i in range(Nsam):\n",
    "        # AMset = AMset.append(AMs.loc[AMs.ind == randomindex1[i]])\n",
    "        AMset = pd.concat([AMset, AMs.loc[AMs.ind == randomindex1[i]]])\n",
    "    \n",
    "    rho, Sp = spearmanr(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    tau, Kp = kendalltau(AMset['Q_S1'], AMset['Q_S2'])\n",
    "\n",
    "    #Marginals\n",
    "    LMU1 = lmom.samlmu(AMset['Q_S1'])\n",
    "    LMU2 = lmom.samlmu(AMset['Q_S2'])\n",
    "\n",
    "    if AM == 'AM1':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgpa(LMU2)  \n",
    "    elif AM == 'AM2':\n",
    "        fit1 = lmom.pelgum(LMU1)\n",
    "        fit2 = lmom.pelgum(LMU2)\n",
    "        \n",
    "    elif AM == 'AM3':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgum(LMU2)\n",
    "\n",
    "    Area = np.zeros(n)\n",
    "    Volume = np.zeros(n)\n",
    "\n",
    "    alpha = 1 / (1-tau)\n",
    "    \n",
    "    #lookup table\n",
    "    x1 = np.arange(0.0000000001, 0.000000001, 0.0000000001)\n",
    "    x2 = x1 * 10\n",
    "    x3 = x2 * 10\n",
    "    x4 = x3 * 10\n",
    "    x5 = x4 * 10\n",
    "    x6 = x5 * 10\n",
    "    x7 = x6 * 10\n",
    "    x8 = x7 * 10\n",
    "    x9 = np.arange(x8[-1]+0.001, 0.999, 0.001)\n",
    "    x10 = np.arange(0.999, 0.9999, 0.0001)\n",
    "    x11 = np.arange(0.9999, 0.99999, 0.00001)\n",
    "    x12 = np.arange(0.99999, 1, 0.000001)\n",
    "    x = np.concatenate((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12))\n",
    "    y = alpha * ((-np.log(x))** alpha)/(x*np.log(x))\n",
    "    ltable = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "    for i in range(n):\n",
    "        u = np.random.rand(1)\n",
    "        t = np.random.rand(1)\n",
    "        phi_u = alpha * ((-np.log(u))**alpha)/(u*np.log(u))\n",
    "        phi_w = phi_u / t\n",
    "        \n",
    "        w = np.interp(phi_w, ltable['y'], ltable['x'])\n",
    "        s = ((-np.log(w)) ** alpha ) - ((-np.log(u)) ** alpha )\n",
    "        v = np.exp(-(s**(1/alpha)))\n",
    "        \n",
    "        if AM == 'AM1':\n",
    "            D1 = lmom.quagev(u, fit1)\n",
    "            D2 = lmom.quagpa(v, fit2)\n",
    "        elif AM == 'AM2':\n",
    "            D1 = lmom.quagum(u, fit1)\n",
    "            D2 = lmom.quagum(v, fit2) \n",
    "        elif AM == 'AM3':\n",
    "            D1 = lmom.quagev(u, fit1)\n",
    "            D2 = lmom.quagum(v, fit2)\n",
    "\n",
    "        Area[i] = fArea(D1, D2)[0]\n",
    "        Volume[i] = fVolume(D1, D2)[0]\n",
    "\n",
    "    return Area, Volume\n",
    "    \n",
    "\n",
    "def ClaR_n2(AM, AMs, Nsam, n):\n",
    "    AMs['ind'] = np.arange(len(AMs))\n",
    "    randomindex1 = np.random.choice(AMs.ind, size=Nsam, replace=False)\n",
    "    AMset = pd.DataFrame()\n",
    "    for i in range(Nsam):\n",
    "        # AMset = AMset.append(AMs.loc[AMs.ind == randomindex1[i]])\n",
    "        AMset = pd.concat([AMset, AMs.loc[AMs.ind == randomindex1[i]]])\n",
    "    \n",
    "    rho, Sp = spearmanr(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    tau, Kp = kendalltau(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    \n",
    "    #Marginals\n",
    "    LMU1 = lmom.samlmu(AMset['Q_S1'])\n",
    "    LMU2 = lmom.samlmu(AMset['Q_S2'])\n",
    "\n",
    "    if AM == 'AM1':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgpa(LMU2)  \n",
    "    elif AM == 'AM2':\n",
    "        fit1 = lmom.pelgum(LMU1)\n",
    "        fit2 = lmom.pelgum(LMU2)\n",
    "    elif AM == 'AM3':\n",
    "        fit1 = lmom.pelgev(LMU1)\n",
    "        fit2 = lmom.pelgum(LMU2)\n",
    "        \n",
    "    Area = np.zeros(n)\n",
    "    Volume = np.zeros(n)\n",
    "    \n",
    "    alpha = (2 * tau) / (1-tau)\n",
    "    \n",
    "    #lookup table\n",
    "    x1 = np.arange(0.0000000001, 0.000000001, 0.0000000001)\n",
    "    x2 = x1 * 10\n",
    "    x3 = x2 * 10\n",
    "    x4 = x3 * 10\n",
    "    x5 = x4 * 10\n",
    "    x6 = x5 * 10\n",
    "    x7 = x6 * 10\n",
    "    x8 = x7 * 10\n",
    "    x9 = np.arange(x8[-1]+0.001, 0.999, 0.001)\n",
    "    x10 = np.arange(0.999, 0.9999, 0.0001)\n",
    "    x11 = np.arange(0.9999, 0.99999, 0.00001)\n",
    "    x12 = np.arange(0.99999, 1, 0.000001)\n",
    "    x = np.concatenate((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12))\n",
    "    y = - ( x ** ( -1 - alpha))\n",
    "    ltable = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "    # for i in range(n):\n",
    "    iter = 0\n",
    "    while iter<n:\n",
    "        u = np.random.rand(1)\n",
    "        t = np.random.rand(1)\n",
    "        phi_u =  -(u ** (-1 - alpha))\n",
    "        phi_w = phi_u / t\n",
    "        \n",
    "        w = np.interp(phi_w, ltable['y'], ltable['x'])\n",
    "        s = ((w ** (-alpha))-1)/alpha-((u ** (-alpha))-1)/alpha\n",
    "        v = (alpha * s +1) ** (-1/alpha)\n",
    "\n",
    "        if AM == 'AM1':\n",
    "            D1 = lmom.quagev(u, fit1)\n",
    "            D2 = lmom.quagpa(v, fit2)\n",
    "        elif AM == 'AM2':\n",
    "            D1 = lmom.quagum(u, fit1)\n",
    "            D2 = lmom.quagum(v, fit2)\n",
    "        elif AM == 'AM3':\n",
    "            D1 = lmom.quagev(u, fit1)\n",
    "            D2 = lmom.quagum(v, fit2)\n",
    "\n",
    "        if D1 != None:\n",
    "            if D2 != None:\n",
    "                Area[iter] = fArea(D1, D2)[0]\n",
    "                Volume[iter] = fVolume(D1, D2)[0]\n",
    "                iter+=1\n",
    "        else:\n",
    "            iter+=0\n",
    "            \n",
    "    return Area, Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd alternative for marginals SET 2 & SET3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb = 100 #Bootstrapping experiment\n",
    "\n",
    "T = [2, 5, 10, 20, 50, 100, 200, 500, 1000, 5000]\n",
    "Pexc = [1 - 1 / t for t in T]\n",
    "\n",
    "AMs = ['AM2', 'AM3'] #'AM1', 'AM2', 'AM3'\n",
    "n = 200000   # CV=5% for T=500 MCiterations\n",
    "\n",
    "Nsam = 100 #[20, 50, 100, 500, 1000] Size of the random sample\n",
    "\n",
    "for AM in AMs:\n",
    "    print(f'Starting {AM} at {str(datetime.now())}')\n",
    "    if AM == 'AM1':\n",
    "        AMset = AM1 \n",
    "    elif AM == 'AM2':\n",
    "        AMset = AM2\n",
    "    elif AM == 'AM3':\n",
    "        AMset = AM1 \n",
    "    \n",
    "    globals()[f'N{Nsam}_{AM}_Agau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    \n",
    "    for i in range(Nb):\n",
    "        print(f'{i} - {str(datetime.now().time())}')\n",
    "        Area, Volume = GauR_n2(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gau = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gau = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agau'].loc[i] = A_gau\n",
    "        globals()[f'N{Nsam}_{AM}_Vgau'].loc[i] = V_gau\n",
    "\n",
    "        Area, Volume = GumR_n2(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gum = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gum = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agum'].loc[i] = A_gum\n",
    "        globals()[f'N{Nsam}_{AM}_Vgum'].loc[i] = V_gum\n",
    "\n",
    "        Area, Volume = ClaR_n2(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_cla = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_cla = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Acla'].loc[i] = A_cla\n",
    "        globals()[f'N{Nsam}_{AM}_Vcla'].loc[i] = V_cla\n",
    "    \n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\RQ2\\MCruns\\Ts\\N%d\" %Nsam + r\"_\" + AM\n",
    "    desc = r\"_Agau2.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgau2.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Agum2.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgum2.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Acla2.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vcla2.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'].to_pickle(sv+desc)\n",
    "    \n",
    "    print(f'Done {AM} at {str(datetime.now().time())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empirical distribution\n",
    "\n",
    "def GauR_n3emp(AM, AMs, Nsam, n):\n",
    "    AMs['ind'] = np.arange(len(AMs))\n",
    "    randomindex1 = np.random.choice(AMs.ind, size=Nsam, replace=False)\n",
    "    AMset = pd.DataFrame()\n",
    "    for i in range(Nsam):\n",
    "        # AMset = AMset.append(AMs.loc[AMs.ind == randomindex1[i]])\n",
    "        AMset = pd.concat([AMset, AMs.loc[AMs.ind == randomindex1[i]]])\n",
    "    \n",
    "    rho, Sp = spearmanr(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    tau, Kp = kendalltau(AMset['Q_S1'], AMset['Q_S2'])\n",
    "\n",
    "    #Marginals\n",
    "    fp1, xp1 = ecdf(AMs['Q_S1'])\n",
    "    fp2, xp2 = ecdf(AMs['Q_S2'])\n",
    "\n",
    "    Area = np.zeros(n)\n",
    "    Volume = np.zeros(n)\n",
    "    for i in range(n): \n",
    "        p1 = np.random.rand(1)\n",
    "        p2 = np.random.rand(1)\n",
    "        u1 = norm.ppf(p1)\n",
    "        u2 = norm.ppf(p2)\n",
    "        u1_ = u1\n",
    "        u2_ = rho * u1 + np.sqrt(1 - rho**2) * u2\n",
    "        p1_ = norm.cdf(u1_)\n",
    "        p2_ = norm.cdf(u2_)   \n",
    "\n",
    "        D1 = np.interp(p1_, xp1, fp1)\n",
    "        D2 = np.interp(p2_, xp2, fp2) \n",
    "       \n",
    "        Area[i] = fArea(D1, D2)[0]\n",
    "        Volume[i] = fVolume(D1, D2)[0]\n",
    "        \n",
    "    return Area, Volume\n",
    "\n",
    "def GumR_n3emp(AM, AMs, Nsam, n):\n",
    "    AMs['ind'] = np.arange(len(AMs))\n",
    "    randomindex1 = np.random.choice(AMs.ind, size=Nsam, replace=False)\n",
    "    AMset = pd.DataFrame()\n",
    "    for i in range(Nsam):\n",
    "        # AMset = AMset.append(AMs.loc[AMs.ind == randomindex1[i]])\n",
    "        AMset = pd.concat([AMset, AMs.loc[AMs.ind == randomindex1[i]]])\n",
    "    \n",
    "    rho, Sp = spearmanr(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    tau, Kp = kendalltau(AMset['Q_S1'], AMset['Q_S2'])\n",
    "\n",
    "    #Marginals\n",
    "    fp1, xp1 = ecdf(AMs['Q_S1'])\n",
    "    fp2, xp2 = ecdf(AMs['Q_S2'])\n",
    "\n",
    "    Area = np.zeros(n)\n",
    "    Volume = np.zeros(n)\n",
    "\n",
    "    alpha = 1 / (1-tau)\n",
    "    \n",
    "    #lookup table\n",
    "    x1 = np.arange(0.0000000001, 0.000000001, 0.0000000001)\n",
    "    x2 = x1 * 10\n",
    "    x3 = x2 * 10\n",
    "    x4 = x3 * 10\n",
    "    x5 = x4 * 10\n",
    "    x6 = x5 * 10\n",
    "    x7 = x6 * 10\n",
    "    x8 = x7 * 10\n",
    "    x9 = np.arange(x8[-1]+0.001, 0.999, 0.001)\n",
    "    x10 = np.arange(0.999, 0.9999, 0.0001)\n",
    "    x11 = np.arange(0.9999, 0.99999, 0.00001)\n",
    "    x12 = np.arange(0.99999, 1, 0.000001)\n",
    "    x = np.concatenate((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12))\n",
    "    y = alpha * ((-np.log(x))** alpha)/(x*np.log(x))\n",
    "    ltable = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "    for i in range(n):\n",
    "        u = np.random.rand(1)\n",
    "        t = np.random.rand(1)\n",
    "        phi_u = alpha * ((-np.log(u))**alpha)/(u*np.log(u))\n",
    "        phi_w = phi_u / t\n",
    "        \n",
    "        w = np.interp(phi_w, ltable['y'], ltable['x'])\n",
    "        s = ((-np.log(w)) ** alpha ) - ((-np.log(u)) ** alpha )\n",
    "        v = np.exp(-(s**(1/alpha)))\n",
    "        \n",
    "        D1 = np.interp(u, xp1, fp1)\n",
    "        D2 = np.interp(v, xp2, fp2)\n",
    "\n",
    "        Area[i] = fArea(D1, D2)[0]\n",
    "        Volume[i] = fVolume(D1, D2)[0]\n",
    "\n",
    "    return Area, Volume\n",
    "    \n",
    "\n",
    "def ClaR_n3emp(AM, AMs, Nsam, n):\n",
    "    AMs['ind'] = np.arange(len(AMs))\n",
    "    randomindex1 = np.random.choice(AMs.ind, size=Nsam, replace=False)\n",
    "    AMset = pd.DataFrame()\n",
    "    for i in range(Nsam):\n",
    "        # AMset = AMset.append(AMs.loc[AMs.ind == randomindex1[i]])\n",
    "        AMset = pd.concat([AMset, AMs.loc[AMs.ind == randomindex1[i]]])\n",
    "    \n",
    "    rho, Sp = spearmanr(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    tau, Kp = kendalltau(AMset['Q_S1'], AMset['Q_S2'])\n",
    "    \n",
    "    #Marginals\n",
    "    fp1, xp1 = ecdf(AMs['Q_S1'])\n",
    "    fp2, xp2 = ecdf(AMs['Q_S2'])\n",
    "        \n",
    "    Area = np.zeros(n)\n",
    "    Volume = np.zeros(n)\n",
    "    \n",
    "    alpha = (2 * tau) / (1-tau)\n",
    "    \n",
    "    #lookup table\n",
    "    x1 = np.arange(0.0000000001, 0.000000001, 0.0000000001)\n",
    "    x2 = x1 * 10\n",
    "    x3 = x2 * 10\n",
    "    x4 = x3 * 10\n",
    "    x5 = x4 * 10\n",
    "    x6 = x5 * 10\n",
    "    x7 = x6 * 10\n",
    "    x8 = x7 * 10\n",
    "    x9 = np.arange(x8[-1]+0.001, 0.999, 0.001)\n",
    "    x10 = np.arange(0.999, 0.9999, 0.0001)\n",
    "    x11 = np.arange(0.9999, 0.99999, 0.00001)\n",
    "    x12 = np.arange(0.99999, 1, 0.000001)\n",
    "    x = np.concatenate((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12))\n",
    "    y = - ( x ** ( -1 - alpha))\n",
    "    ltable = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "    # for i in range(n):\n",
    "    iter = 0\n",
    "    while iter<n:\n",
    "        u = np.random.rand(1)\n",
    "        t = np.random.rand(1)\n",
    "        phi_u =  -(u ** (-1 - alpha))\n",
    "        phi_w = phi_u / t\n",
    "        \n",
    "        w = np.interp(phi_w, ltable['y'], ltable['x'])\n",
    "        s = ((w ** (-alpha))-1)/alpha-((u ** (-alpha))-1)/alpha\n",
    "        v = (alpha * s +1) ** (-1/alpha)\n",
    "\n",
    "        D1 = np.interp(u, xp1, fp1)\n",
    "        D2 = np.interp(v, xp2, fp2)\n",
    "\n",
    "        if D1 != None:\n",
    "            if D2 != None:\n",
    "                Area[iter] = fArea(D1, D2)[0]\n",
    "                Volume[iter] = fVolume(D1, D2)[0]\n",
    "                iter+=1\n",
    "        else:\n",
    "            iter+=0\n",
    "            \n",
    "    return Area, Volume   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb = 100 #Bootstrapping experiment\n",
    "\n",
    "T = [2, 5, 10, 20, 50, 100, 200, 500, 1000, 5000]\n",
    "Pexc = [1 - 1 / t for t in T]\n",
    "\n",
    "AMs = ['AM1', 'AM2', 'AM3'] #'AM1', 'AM2', 'AM3'\n",
    "n = 200000   # CV=5% for T=500 MCiterations\n",
    "\n",
    "Nsam = 100 #[20, 50, 100, 500, 1000] Size of the random sample\n",
    "\n",
    "for AM in AMs:\n",
    "    print(f'Starting {AM} at {str(datetime.now())}')\n",
    "    if AM == 'AM1':\n",
    "        AMset = AM1 \n",
    "    elif AM == 'AM2':\n",
    "        AMset = AM2\n",
    "    elif AM == 'AM3':\n",
    "        AMset = AM1 \n",
    "    \n",
    "    globals()[f'N{Nsam}_{AM}_Agau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'] = pd.DataFrame(index=range(Nb), columns=T)\n",
    "    \n",
    "    for i in range(Nb):\n",
    "        print(f'{i} - {str(datetime.now().time())}')\n",
    "        Area, Volume = GauR_n3emp(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gau = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gau = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agau'].loc[i] = A_gau\n",
    "        globals()[f'N{Nsam}_{AM}_Vgau'].loc[i] = V_gau\n",
    "\n",
    "        Area, Volume = GumR_n3emp(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_gum = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_gum = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Agum'].loc[i] = A_gum\n",
    "        globals()[f'N{Nsam}_{AM}_Vgum'].loc[i] = V_gum\n",
    "\n",
    "        Area, Volume = ClaR_n3emp(AM, AMset, Nsam, n)\n",
    "        x, y = ecdf(Area)\n",
    "        A_cla = [empinv(p, x, y) for p in Pexc] #/1000000\n",
    "        x, y = ecdf(Volume)\n",
    "        V_cla = [empinv(p, x, y) for p in Pexc] #/1000000000\n",
    "        globals()[f'N{Nsam}_{AM}_Acla'].loc[i] = A_cla\n",
    "        globals()[f'N{Nsam}_{AM}_Vcla'].loc[i] = V_cla\n",
    "    \n",
    "    sv = r\"P:\\11206883-006-dar-cloud-computing\\GRADE_export\\HYDa\\RQ2\\MCruns\\Ts\\N%d\" %Nsam + r\"_\" + AM\n",
    "    desc = r\"_Agau3emp.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgau3emp.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgau'].to_pickle(sv+desc)\n",
    "    desc = r\"_Agum3emp.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Agum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vgum3emp.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vgum'].to_pickle(sv+desc)\n",
    "    desc = r\"_Acla3emp.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Acla'].to_pickle(sv+desc)\n",
    "    desc = r\"_Vcla3emp.pkl\"\n",
    "    globals()[f'N{Nsam}_{AM}_Vcla'].to_pickle(sv+desc)\n",
    "    \n",
    "    print(f'Done {AM} at {str(datetime.now().time())}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('hydromt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8ba6ae7d4330b9d9ebc798522c4c448c2c2629cb08cc9d246b990170d5c89fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
